import torchimport numpy as npfrom .train import trainfrom .evaluate import evaluatefrom chemprop.bayes.swag import SWAGfrom chemprop.bayes_utils import scheduler_constdef train_swag(        model,        train_data_loader,        val_data_loader,        loss_func,        metric_func,        args,        scaler):        # define no_cov_mat from cov_mat    if args.cov_mat:        no_cov_mat = False    else:        no_cov_mat = True        # instantiate SWAG model    swag_model = SWAG(        model,        no_cov_mat,        args.max_num_models,        var_clamp=1e-30    )    # define optimiser    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr_swag, momentum=args.momentum_swag, weight_decay=args.wd_swag)        # define scheduler    scheduler = scheduler_const(args.lr_swag)    print("----------SWAG training----------")        # training loop    n_iter = 0    for epoch in range(args.epochs_swag):        print(f'SWAG spoch {epoch}')            n_iter = train(                model=model,                data_loader=train_data_loader,                loss_func=loss_func,                optimizer=optimizer,                scheduler=scheduler,                args=args,                n_iter=n_iter,                swag_model=swag_model            )                val_scores = evaluate(                model=model,                data_loader=val_data_loader,                args=args,                num_tasks=args.num_tasks,                metric_func=metric_func,                dataset_type=args.dataset_type,                scaler=scaler            )                # Average validation score        avg_val_score = np.nanmean(val_scores)        print(f'Validation {args.metric} = {avg_val_score:.6f}')            return swag_model    