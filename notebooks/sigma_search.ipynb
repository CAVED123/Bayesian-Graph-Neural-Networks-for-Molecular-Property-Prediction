{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "from logging import Logger\n",
    "from typing import List\n",
    "from tqdm import trange\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/georgelamb/Documents/GitHub/chempropBayes\n"
     ]
    }
   ],
   "source": [
    "# cd to chempropBayes\n",
    "%cd '/Users/georgelamb/Documents/GitHub/chempropBayes'\n",
    "from chemprop.train.run_training import run_training\n",
    "from chemprop.args import TrainArgs\n",
    "from chemprop.data.utils import get_class_sizes, get_data, get_task_names, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainArgs()\n",
    "args.from_dict({\n",
    "    'dataset_type': 'regression',\n",
    "    'data_path': '/Users/georgelamb/Documents/GitHub/chempropBayes/data/QM9.csv'\n",
    "})\n",
    "\n",
    "# location for model checkpoints to be saved\n",
    "args.save_dir = '/Users/georgelamb/Documents/GitHub/chempropBayes/log'\n",
    "\n",
    "args.seed = 0 # data seed\n",
    "args.max_data_size = 50000\n",
    "args.features_path = None\n",
    "args.features_generator = None\n",
    "args.split_type = 'scaffold_balanced'\n",
    "args.split_sizes = (0.64, 0.16, 0.2)\n",
    "args.metric = 'mae'\n",
    "args.pytorch_seed = 0 # initial weights\n",
    "args.atom_messages = False\n",
    "args.undirected = False\n",
    "args.bias = False\n",
    "args.hidden_size = 500\n",
    "args.depth = 5\n",
    "args.ffn_hidden_size = args.hidden_size\n",
    "args.ffn_num_layers = 3\n",
    "args.activation = 'ReLU'\n",
    "args.ensemble_size = 1\n",
    "args.samples = 1\n",
    "args.log_frequency = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP\n",
    "args.epochs = 100\n",
    "args.init_log_noise = -2\n",
    "\n",
    "args.warmup_epochs = 2.0\n",
    "args.init_lr = 1e-4\n",
    "args.max_lr = 1e-3\n",
    "args.final_lr = 1e-4\n",
    "\n",
    "args.wandb_name = 'MAP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command line\n",
      "python /Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py -f /Users/georgelamb/Library/Jupyter/runtime/kernel-4813dbc2-0976-47a7-8cac-ceb3ea28407e.json\n",
      "Args\n",
      "{'activation': 'ReLU',\n",
      " 'atom_messages': False,\n",
      " 'batch_size_gp': 100,\n",
      " 'batch_size_sgld': 50,\n",
      " 'bbp': False,\n",
      " 'bias': False,\n",
      " 'block': True,\n",
      " 'burnin_epochs': 10,\n",
      " 'c_swag': 0,\n",
      " 'cache_cutoff': 10000,\n",
      " 'class_balance': False,\n",
      " 'config_path': None,\n",
      " 'cov_mat': False,\n",
      " 'crossval_index_dir': None,\n",
      " 'crossval_index_file': None,\n",
      " 'crossval_index_sets': None,\n",
      " 'data_path': '/Users/georgelamb/Documents/GitHub/chempropBayes/data/QM9.csv',\n",
      " 'dataset_type': 'regression',\n",
      " 'depth': 5,\n",
      " 'dropout': 0.0,\n",
      " 'dropout_FFNonly': False,\n",
      " 'ensemble_size': 1,\n",
      " 'epochs': 100,\n",
      " 'epochs_gp': 100,\n",
      " 'epochs_swag': 0,\n",
      " 'features_generator': None,\n",
      " 'features_only': False,\n",
      " 'features_path': None,\n",
      " 'features_size': None,\n",
      " 'ffn_hidden_size': 500,\n",
      " 'ffn_num_layers': 3,\n",
      " 'final_lr': 0.0001,\n",
      " 'final_lr_gp': 0.0001,\n",
      " 'folds_file': None,\n",
      " 'gp': False,\n",
      " 'hidden_size': 500,\n",
      " 'init_log_noise': -2,\n",
      " 'init_log_noise_sgld': -2,\n",
      " 'init_lr': 0.0001,\n",
      " 'init_lr_gp': 0.0001,\n",
      " 'log_frequency': 640,\n",
      " 'log_frequency_gp': 100,\n",
      " 'log_frequency_sgld': 0,\n",
      " 'lr_sgld': 0.0001,\n",
      " 'lr_swag': 0.0001,\n",
      " 'max_data_size': 50000,\n",
      " 'max_lr': 0.001,\n",
      " 'max_lr_gp': 0.001,\n",
      " 'max_num_models': 0,\n",
      " 'metric': 'mae',\n",
      " 'minimize_score': True,\n",
      " 'mix_epochs': 1,\n",
      " 'momentum_swag': 0.9,\n",
      " 'multiclass_num_classes': 3,\n",
      " 'num_folds': 1,\n",
      " 'num_inducing_points': 2000,\n",
      " 'num_lrs': 1,\n",
      " 'num_tasks': None,\n",
      " 'prior_sig_bbp': 1,\n",
      " 'pytorch_seed': 0,\n",
      " 'quiet': False,\n",
      " 'samples': 1,\n",
      " 'save_dir': '/Users/georgelamb/Documents/GitHub/chempropBayes/log',\n",
      " 'save_smiles_splits': False,\n",
      " 'seed': 0,\n",
      " 'separate_test_features_path': None,\n",
      " 'separate_test_path': None,\n",
      " 'separate_val_features_path': None,\n",
      " 'separate_val_path': None,\n",
      " 'sgld': False,\n",
      " 'show_individual_scores': False,\n",
      " 'split_sizes': (0.64, 0.16, 0.2),\n",
      " 'split_type': 'scaffold_balanced',\n",
      " 'swag': False,\n",
      " 'target_columns': None,\n",
      " 'task_names': None,\n",
      " 'test': False,\n",
      " 'test_dropout': False,\n",
      " 'test_fold_index': None,\n",
      " 'train_data_size': None,\n",
      " 'undirected': False,\n",
      " 'unfreeze_epoch_gp': 50,\n",
      " 'use_input_features': False,\n",
      " 'val_fold_index': None,\n",
      " 'wandb_name': 'MAP',\n",
      " 'warmup_epochs': 2.0,\n",
      " 'warmup_epochs_gp': 4,\n",
      " 'wd_swag': 0,\n",
      " 'weight_decay': 0.01,\n",
      " 'weight_decay_sgld': 0}\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39893it [00:00, 79691.95it/s] \n",
      "100%|██████████| 50000/50000 [00:00<00:00, 402540.60it/s]\n",
      "100%|██████████| 50000/50000 [00:03<00:00, 13607.10it/s]\n",
      "  4%|▍         | 1994/50000 [00:00<00:02, 19939.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks = 12\n",
      "Splitting data with seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:04<00:00, 11467.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size = 50,000 | train size = 32,000 | val size = 8,000 | test size = 10,000\n",
      "Fitting scaler\n",
      "Building model 0\n",
      "MoleculeModel(\n",
      "  (encoder): MPN(\n",
      "    (encoder): MPNEncoder(\n",
      "      (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      (act_func): ReLU()\n",
      "      (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
      "      (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
      "      (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (ffn): Sequential(\n",
      "    (0): Dropout(p=0.0, inplace=False)\n",
      "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.0, inplace=False)\n",
      "    (7): Linear(in_features=500, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 1,147,524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/georgelamb19/chempropBayes\" target=\"_blank\">https://app.wandb.ai/georgelamb19/chempropBayes</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/georgelamb19/chempropBayes/runs/62d0b6jg\" target=\"_blank\">https://app.wandb.ai/georgelamb19/chempropBayes/runs/62d0b6jg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Loss = 7.9719e+01, PNorm = 41.9207, GNorm = 661.8070, lr_0 = 5.5070e-04, lr_1 = 5.5070e-04, lr_2 = 5.5070e-04\n",
      "Validation mae = 13.798800\n",
      "Epoch 1\n",
      "Loss = 1.8579e+01, PNorm = 41.2425, GNorm = 282.6487, lr_0 = 9.9996e-04, lr_1 = 9.9996e-04, lr_2 = 9.9996e-04\n",
      "Validation mae = 10.841062\n",
      "Epoch 2\n",
      "Loss = -8.2142e-02, PNorm = 40.3308, GNorm = 198.7011, lr_0 = 9.7674e-04, lr_1 = 9.7674e-04, lr_2 = 9.7674e-04\n",
      "Validation mae = 9.521616\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-50:\n",
      "Process Process-53:\n",
      "Process Process-54:\n",
      "Process Process-51:\n",
      "Process Process-49:\n",
      "Process Process-56:\n",
      "Process Process-55:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8859e867a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 962, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 942, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/Applications/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-84f7d9cacaf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_MAP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/chempropBayes/chemprop/train/run_training.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(args, logger)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                 \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             )\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExponentialLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/chempropBayes/chemprop/train/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, loss_func, optimizer, scheduler, args, n_iter, logger, writer, swag_model, sgld_switch, gp_switch, likelihood, bbp_switch)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmol_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/chempropBayes/chemprop/models/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeaturize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Don't apply sigmoid during training b/c using BCEWithLogitsLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/chempropBayes/chemprop/models/mpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch, features_batch, sample)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/chempropBayes/chemprop/models/mpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mol_graph, features_batch, sample)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0ma_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnei_a_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# num_atoms x hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mrev_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb2revb\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# num_bonds x hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_message\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb2a\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrev_message\u001b[0m  \u001b[0;31m# num_bonds x hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _init_jupyter.<locals>.cleanup at 0x7f883f79b560> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/__init__.py\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# shutdown async logger because _user_process_finished isn't called in jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mshutdown_async_log_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_jupyter_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_orig_post_run\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post_run_cell\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_post_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/wandb_run.py\u001b[0m in \u001b[0;36m_stop_jupyter_agent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_stop_jupyter_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jupyter_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/jupyter.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmirror_stdout_stderr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaused\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, exitcode)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloud\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stopping streaming files and file change observer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_file_syncing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36m_end_file_syncing\u001b[0;34m(self, exitcode)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# TODO: there was a case where _file_event_handlers was getting modified in the loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_event_handlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_pusher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_stream_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mfinish\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tailer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tailer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tailer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/wandb/run_manager.py\u001b[0m in \u001b[0;36mstop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args.weight_decay = 0.01\n",
    "results_MAP = run_training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight decay of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5903it [00:00, 59027.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command line\n",
      "python /Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py -f /Users/georgelamb/Library/Jupyter/runtime/kernel-3ce28114-5e5a-455d-a29b-0c200a224367.json\n",
      "Args\n",
      "{'activation': 'ReLU',\n",
      " 'atom_messages': False,\n",
      " 'batch_size_gp': 100,\n",
      " 'batch_size_sgld': 50,\n",
      " 'bbp': False,\n",
      " 'bias': False,\n",
      " 'block': True,\n",
      " 'burnin_epochs': 10,\n",
      " 'c_swag': 0,\n",
      " 'cache_cutoff': 10000,\n",
      " 'class_balance': False,\n",
      " 'config_path': None,\n",
      " 'cov_mat': False,\n",
      " 'crossval_index_dir': None,\n",
      " 'crossval_index_file': None,\n",
      " 'crossval_index_sets': None,\n",
      " 'data_path': '/Users/georgelamb/Documents/GitHub/chempropBayes/data/QM9.csv',\n",
      " 'dataset_type': 'regression',\n",
      " 'depth': 5,\n",
      " 'dropout': 0.0,\n",
      " 'dropout_FFNonly': False,\n",
      " 'ensemble_size': 1,\n",
      " 'epochs': 100,\n",
      " 'epochs_gp': 100,\n",
      " 'epochs_swag': 0,\n",
      " 'features_generator': None,\n",
      " 'features_only': False,\n",
      " 'features_path': None,\n",
      " 'features_size': None,\n",
      " 'ffn_hidden_size': 500,\n",
      " 'ffn_num_layers': 3,\n",
      " 'final_lr': 0.0001,\n",
      " 'final_lr_gp': 0.0001,\n",
      " 'folds_file': None,\n",
      " 'gp': False,\n",
      " 'hidden_size': 500,\n",
      " 'init_log_noise': -2,\n",
      " 'init_log_noise_sgld': -2,\n",
      " 'init_lr': 0.0001,\n",
      " 'init_lr_gp': 0.0001,\n",
      " 'log_frequency': 640,\n",
      " 'log_frequency_gp': 100,\n",
      " 'log_frequency_sgld': 0,\n",
      " 'lr_sgld': 0.0001,\n",
      " 'lr_swag': 0.0001,\n",
      " 'max_data_size': 50000,\n",
      " 'max_lr': 0.001,\n",
      " 'max_lr_gp': 0.001,\n",
      " 'max_num_models': 0,\n",
      " 'metric': 'mae',\n",
      " 'minimize_score': True,\n",
      " 'mix_epochs': 1,\n",
      " 'momentum_swag': 0.9,\n",
      " 'multiclass_num_classes': 3,\n",
      " 'num_folds': 1,\n",
      " 'num_inducing_points': 2000,\n",
      " 'num_lrs': 1,\n",
      " 'num_tasks': None,\n",
      " 'prior_sig_bbp': 1,\n",
      " 'pytorch_seed': 0,\n",
      " 'quiet': False,\n",
      " 'samples': 1,\n",
      " 'save_dir': '/Users/georgelamb/Documents/GitHub/chempropBayes/log',\n",
      " 'save_smiles_splits': False,\n",
      " 'seed': 0,\n",
      " 'separate_test_features_path': None,\n",
      " 'separate_test_path': None,\n",
      " 'separate_val_features_path': None,\n",
      " 'separate_val_path': None,\n",
      " 'sgld': False,\n",
      " 'show_individual_scores': False,\n",
      " 'split_sizes': (0.64, 0.16, 0.2),\n",
      " 'split_type': 'scaffold_balanced',\n",
      " 'swag': False,\n",
      " 'target_columns': None,\n",
      " 'task_names': None,\n",
      " 'test': False,\n",
      " 'test_dropout': False,\n",
      " 'test_fold_index': None,\n",
      " 'train_data_size': None,\n",
      " 'undirected': False,\n",
      " 'unfreeze_epoch_gp': 50,\n",
      " 'use_input_features': False,\n",
      " 'val_fold_index': None,\n",
      " 'warmup_epochs': 2.0,\n",
      " 'warmup_epochs_gp': 4,\n",
      " 'wd_swag': 0,\n",
      " 'weight_decay': 0.01,\n",
      " 'weight_decay_sgld': 0}\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49476it [00:00, 88270.38it/s]\n",
      "100%|██████████| 50000/50000 [00:00<00:00, 308299.52it/s]\n",
      "100%|██████████| 50000/50000 [00:03<00:00, 13655.80it/s]\n",
      "  4%|▍         | 1991/50000 [00:00<00:02, 19900.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tasks = 12\n",
      "Splitting data with seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:04<00:00, 11510.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size = 50,000 | train size = 32,000 | val size = 8,000 | test size = 10,000\n",
      "Fitting scaler\n",
      "Building model 0\n",
      "MoleculeModel(\n",
      "  (encoder): MPN(\n",
      "    (encoder): MPNEncoder(\n",
      "      (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "      (act_func): ReLU()\n",
      "      (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
      "      (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
      "      (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (ffn): Sequential(\n",
      "    (0): Dropout(p=0.0, inplace=False)\n",
      "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.0, inplace=False)\n",
      "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.0, inplace=False)\n",
      "    (7): Linear(in_features=500, out_features=12, bias=True)\n",
      "  )\n",
      ")\n",
      "Number of parameters = 1,147,524\n",
      "Epoch 0\n",
      "Loss = 1.5944e+00, PNorm = 41.9207, GNorm = 661.8070, lr_0 = 5.5070e-04, lr_1 = 5.5070e-04, lr_2 = 5.5070e-04\n",
      "Parameter containing:\n",
      "tensor([-1.8532, -1.8879, -1.8885, -1.9193, -1.8958, -1.8836, -1.9295, -1.8828,\n",
      "        -1.8853, -1.8882, -1.8872, -1.8859], requires_grad=True)\n",
      "Validation mae = 13.798800\n",
      "Epoch 1\n",
      "Loss = 3.7158e-01, PNorm = 41.2425, GNorm = 282.6487, lr_0 = 9.9996e-04, lr_1 = 9.9996e-04, lr_2 = 9.9996e-04\n",
      "Parameter containing:\n",
      "tensor([-1.6093, -1.7071, -1.6917, -1.8059, -1.7327, -1.7043, -1.8017, -1.6880,\n",
      "        -1.6986, -1.7034, -1.7015, -1.6990], requires_grad=True)\n",
      "Validation mae = 10.841062\n",
      "Epoch 2\n",
      "Loss = -1.6428e-03, PNorm = 40.3308, GNorm = 198.7011, lr_0 = 9.7674e-04, lr_1 = 9.7674e-04, lr_2 = 9.7674e-04\n",
      "Parameter containing:\n",
      "tensor([-1.3954, -1.5732, -1.5215, -1.7222, -1.5973, -1.5716, -1.7172, -1.5448,\n",
      "        -1.5650, -1.5706, -1.5686, -1.5655], requires_grad=True)\n",
      "Validation mae = 9.521616\n",
      "Epoch 3\n",
      "Loss = -1.3775e-01, PNorm = 39.0925, GNorm = 65.7997, lr_0 = 9.5406e-04, lr_1 = 9.5406e-04, lr_2 = 9.5406e-04\n",
      "Parameter containing:\n",
      "tensor([-1.2305, -1.5022, -1.4066, -1.6800, -1.5124, -1.4875, -1.6967, -1.4690,\n",
      "        -1.5042, -1.5097, -1.5077, -1.5046], requires_grad=True)\n",
      "Validation mae = 7.030742\n",
      "Epoch 4\n",
      "Loss = -1.8695e-01, PNorm = 37.7336, GNorm = 183.1406, lr_0 = 9.3191e-04, lr_1 = 9.3191e-04, lr_2 = 9.3191e-04\n",
      "Parameter containing:\n",
      "tensor([-1.1017, -1.4615, -1.3279, -1.6715, -1.4674, -1.4313, -1.7201, -1.4272,\n",
      "        -1.4816, -1.4863, -1.4846, -1.4818], requires_grad=True)\n",
      "Validation mae = 6.906723\n",
      "Epoch 5\n",
      "Loss = -2.0806e-01, PNorm = 36.3119, GNorm = 109.5357, lr_0 = 9.1026e-04, lr_1 = 9.1026e-04, lr_2 = 9.1026e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9898, -1.4437, -1.2698, -1.6648, -1.4416, -1.3947, -1.7542, -1.4060,\n",
      "        -1.4841, -1.4875, -1.4863, -1.4835], requires_grad=True)\n",
      "Validation mae = 6.181585\n",
      "Epoch 6\n",
      "Loss = -2.2122e-01, PNorm = 34.8903, GNorm = 63.1697, lr_0 = 8.8913e-04, lr_1 = 8.8913e-04, lr_2 = 8.8913e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8977, -1.4430, -1.2284, -1.6782, -1.4327, -1.3641, -1.8025, -1.4025,\n",
      "        -1.5066, -1.5087, -1.5079, -1.5056], requires_grad=True)\n",
      "Validation mae = 5.682122\n",
      "Epoch 7\n",
      "Loss = -2.2026e-01, PNorm = 33.7055, GNorm = 39.9195, lr_0 = 8.6848e-04, lr_1 = 8.6848e-04, lr_2 = 8.6848e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8198, -1.4363, -1.2048, -1.6937, -1.4368, -1.3423, -1.8022, -1.3902,\n",
      "        -1.5170, -1.5180, -1.5172, -1.5152], requires_grad=True)\n",
      "Validation mae = 5.809334\n",
      "Epoch 8\n",
      "Loss = -2.2802e-01, PNorm = 32.5644, GNorm = 55.0691, lr_0 = 8.4831e-04, lr_1 = 8.4831e-04, lr_2 = 8.4831e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7604, -1.4443, -1.1963, -1.7006, -1.4425, -1.3350, -1.8165, -1.3938,\n",
      "        -1.5318, -1.5315, -1.5313, -1.5296], requires_grad=True)\n",
      "Validation mae = 6.597239\n",
      "Epoch 9\n",
      "Loss = -2.3433e-01, PNorm = 31.5209, GNorm = 45.2407, lr_0 = 8.2861e-04, lr_1 = 8.2861e-04, lr_2 = 8.2861e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7144, -1.4695, -1.1925, -1.7309, -1.4576, -1.3334, -1.8699, -1.4152,\n",
      "        -1.5696, -1.5688, -1.5685, -1.5676], requires_grad=True)\n",
      "Validation mae = 5.627945\n",
      "Epoch 10\n",
      "Loss = -2.4246e-01, PNorm = 30.5081, GNorm = 69.4833, lr_0 = 8.0937e-04, lr_1 = 8.0937e-04, lr_2 = 8.0937e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6864, -1.5121, -1.2061, -1.7519, -1.4778, -1.3601, -1.9322, -1.4624,\n",
      "        -1.6268, -1.6258, -1.6254, -1.6245], requires_grad=True)\n",
      "Validation mae = 5.229197\n",
      "Epoch 11\n",
      "Loss = -2.4796e-01, PNorm = 29.7045, GNorm = 94.8460, lr_0 = 7.9058e-04, lr_1 = 7.9058e-04, lr_2 = 7.9058e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6769, -1.5594, -1.1948, -1.7652, -1.4782, -1.3875, -1.9736, -1.5024,\n",
      "        -1.6842, -1.6832, -1.6827, -1.6821], requires_grad=True)\n",
      "Validation mae = 6.371209\n",
      "Epoch 12\n",
      "Loss = -2.4715e-01, PNorm = 29.4588, GNorm = 168.9696, lr_0 = 7.7222e-04, lr_1 = 7.7222e-04, lr_2 = 7.7222e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6648, -1.5633, -1.2124, -1.7860, -1.5050, -1.3849, -1.9798, -1.4921,\n",
      "        -1.6869, -1.6861, -1.6855, -1.6846], requires_grad=True)\n",
      "Validation mae = 7.407072\n",
      "Epoch 13\n",
      "Loss = -2.5974e-01, PNorm = 28.9369, GNorm = 49.2256, lr_0 = 7.5428e-04, lr_1 = 7.5428e-04, lr_2 = 7.5428e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6668, -1.6119, -1.2277, -1.8070, -1.5159, -1.3974, -2.0189, -1.5295,\n",
      "        -1.7394, -1.7381, -1.7382, -1.7372], requires_grad=True)\n",
      "Validation mae = 4.448963\n",
      "Epoch 14\n",
      "Loss = -2.6280e-01, PNorm = 28.6947, GNorm = 101.4603, lr_0 = 7.3677e-04, lr_1 = 7.3677e-04, lr_2 = 7.3677e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6586, -1.6304, -1.2291, -1.8399, -1.5393, -1.4178, -2.0476, -1.5642,\n",
      "        -1.7729, -1.7716, -1.7718, -1.7710], requires_grad=True)\n",
      "Validation mae = 4.952773\n",
      "Epoch 15\n",
      "Loss = -2.7586e-01, PNorm = 28.1179, GNorm = 77.8656, lr_0 = 7.1966e-04, lr_1 = 7.1966e-04, lr_2 = 7.1966e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6720, -1.6843, -1.2624, -1.8721, -1.5753, -1.4570, -2.1046, -1.6176,\n",
      "        -1.8225, -1.8210, -1.8216, -1.8214], requires_grad=True)\n",
      "Validation mae = 4.114151\n",
      "Epoch 16\n",
      "Loss = -2.8039e-01, PNorm = 28.0333, GNorm = 65.1494, lr_0 = 7.0295e-04, lr_1 = 7.0295e-04, lr_2 = 7.0295e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6705, -1.7124, -1.2521, -1.8554, -1.5691, -1.4776, -2.1434, -1.6376,\n",
      "        -1.8613, -1.8601, -1.8602, -1.8602], requires_grad=True)\n",
      "Validation mae = 4.636137\n",
      "Epoch 17\n",
      "Loss = -2.8644e-01, PNorm = 27.9090, GNorm = 75.0274, lr_0 = 6.8662e-04, lr_1 = 6.8662e-04, lr_2 = 6.8662e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6878, -1.7336, -1.2786, -1.8714, -1.5800, -1.4921, -2.1704, -1.6629,\n",
      "        -1.8912, -1.8899, -1.8900, -1.8899], requires_grad=True)\n",
      "Validation mae = 4.587637\n",
      "Epoch 18\n",
      "Loss = -2.9506e-01, PNorm = 27.7169, GNorm = 100.9587, lr_0 = 6.7068e-04, lr_1 = 6.7068e-04, lr_2 = 6.7068e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6834, -1.7701, -1.2846, -1.9124, -1.6111, -1.5144, -2.2082, -1.7016,\n",
      "        -1.9332, -1.9321, -1.9320, -1.9323], requires_grad=True)\n",
      "Validation mae = 4.166359\n",
      "Epoch 19\n",
      "Loss = -3.0687e-01, PNorm = 27.4102, GNorm = 34.5717, lr_0 = 6.5510e-04, lr_1 = 6.5510e-04, lr_2 = 6.5510e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6973, -1.8082, -1.3331, -1.9421, -1.6564, -1.5398, -2.2520, -1.7396,\n",
      "        -1.9791, -1.9776, -1.9776, -1.9781], requires_grad=True)\n",
      "Validation mae = 3.873305\n",
      "Epoch 20\n",
      "Loss = -2.9923e-01, PNorm = 27.7702, GNorm = 68.2582, lr_0 = 6.3989e-04, lr_1 = 6.3989e-04, lr_2 = 6.3989e-04\n",
      "Parameter containing:\n",
      "tensor([-0.6940, -1.8090, -1.2981, -1.8947, -1.6173, -1.5377, -2.2636, -1.7303,\n",
      "        -1.9835, -1.9822, -1.9820, -1.9823], requires_grad=True)\n",
      "Validation mae = 4.449905\n",
      "Epoch 21\n",
      "Loss = -3.2191e-01, PNorm = 27.0900, GNorm = 52.0274, lr_0 = 6.2503e-04, lr_1 = 6.2503e-04, lr_2 = 6.2503e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7187, -1.8664, -1.3594, -1.9826, -1.6885, -1.5716, -2.3168, -1.7954,\n",
      "        -2.0445, -2.0433, -2.0432, -2.0436], requires_grad=True)\n",
      "Validation mae = 3.559089\n",
      "Epoch 22\n",
      "Loss = -3.1227e-01, PNorm = 27.2880, GNorm = 85.3197, lr_0 = 6.1052e-04, lr_1 = 6.1052e-04, lr_2 = 6.1052e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7109, -1.8811, -1.3566, -1.9738, -1.6821, -1.5848, -2.3405, -1.8040,\n",
      "        -2.0597, -2.0586, -2.0582, -2.0586], requires_grad=True)\n",
      "Validation mae = 4.389820\n",
      "Epoch 23\n",
      "Loss = -3.0326e-01, PNorm = 27.4379, GNorm = 75.8039, lr_0 = 5.9634e-04, lr_1 = 5.9634e-04, lr_2 = 5.9634e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7137, -1.8689, -1.3586, -1.9667, -1.6890, -1.5820, -2.3237, -1.7897,\n",
      "        -2.0443, -2.0433, -2.0430, -2.0432], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mae = 3.665068\n",
      "Epoch 24\n",
      "Loss = -3.2856e-01, PNorm = 27.1110, GNorm = 59.0229, lr_0 = 5.8249e-04, lr_1 = 5.8249e-04, lr_2 = 5.8249e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7251, -1.9034, -1.3880, -2.0041, -1.7145, -1.6125, -2.3558, -1.8251,\n",
      "        -2.0819, -2.0811, -2.0809, -2.0811], requires_grad=True)\n",
      "Validation mae = 3.617521\n",
      "Epoch 25\n",
      "Loss = -3.0456e-01, PNorm = 27.6068, GNorm = 59.5624, lr_0 = 5.6897e-04, lr_1 = 5.6897e-04, lr_2 = 5.6897e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7089, -1.8806, -1.3593, -1.9620, -1.6813, -1.5939, -2.3448, -1.7998,\n",
      "        -2.0586, -2.0576, -2.0574, -2.0573], requires_grad=True)\n",
      "Validation mae = 4.015478\n",
      "Epoch 26\n",
      "Loss = -3.3729e-01, PNorm = 27.1543, GNorm = 95.2865, lr_0 = 5.5575e-04, lr_1 = 5.5575e-04, lr_2 = 5.5575e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7279, -1.9261, -1.4002, -2.0273, -1.7368, -1.6262, -2.3813, -1.8483,\n",
      "        -2.1037, -2.1030, -2.1027, -2.1026], requires_grad=True)\n",
      "Validation mae = 3.715247\n",
      "Epoch 27\n",
      "Loss = -3.3862e-01, PNorm = 27.0312, GNorm = 128.9047, lr_0 = 5.4285e-04, lr_1 = 5.4285e-04, lr_2 = 5.4285e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7359, -1.9581, -1.4222, -2.0516, -1.7669, -1.6452, -2.4114, -1.8790,\n",
      "        -2.1389, -2.1384, -2.1380, -2.1378], requires_grad=True)\n",
      "Validation mae = 3.508634\n",
      "Epoch 28\n",
      "Loss = -3.4525e-01, PNorm = 26.8423, GNorm = 198.8944, lr_0 = 5.3024e-04, lr_1 = 5.3024e-04, lr_2 = 5.3024e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7509, -1.9880, -1.4422, -2.0657, -1.7742, -1.6642, -2.4373, -1.9059,\n",
      "        -2.1720, -2.1714, -2.1711, -2.1709], requires_grad=True)\n",
      "Validation mae = 5.543483\n",
      "Epoch 29\n",
      "Loss = -3.4338e-01, PNorm = 26.8935, GNorm = 51.3337, lr_0 = 5.1793e-04, lr_1 = 5.1793e-04, lr_2 = 5.1793e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7514, -2.0059, -1.4488, -2.0676, -1.7808, -1.6730, -2.4552, -1.9205,\n",
      "        -2.1909, -2.1903, -2.1900, -2.1899], requires_grad=True)\n",
      "Validation mae = 3.530018\n",
      "Epoch 30\n",
      "Loss = -3.4432e-01, PNorm = 26.9453, GNorm = 302.8772, lr_0 = 5.0590e-04, lr_1 = 5.0590e-04, lr_2 = 5.0590e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7434, -2.0157, -1.4412, -2.0690, -1.7817, -1.6829, -2.4749, -1.9295,\n",
      "        -2.2094, -2.2089, -2.2084, -2.2083], requires_grad=True)\n",
      "Validation mae = 3.439315\n",
      "Epoch 31\n",
      "Loss = -3.5323e-01, PNorm = 26.8331, GNorm = 55.2886, lr_0 = 4.9415e-04, lr_1 = 4.9415e-04, lr_2 = 4.9415e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7601, -2.0361, -1.4585, -2.1101, -1.8070, -1.6946, -2.4928, -1.9508,\n",
      "        -2.2288, -2.2284, -2.2278, -2.2278], requires_grad=True)\n",
      "Validation mae = 3.238680\n",
      "Epoch 32\n",
      "Loss = -3.4363e-01, PNorm = 27.0005, GNorm = 38.0064, lr_0 = 4.8268e-04, lr_1 = 4.8268e-04, lr_2 = 4.8268e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7669, -2.0401, -1.4648, -2.0933, -1.8042, -1.6953, -2.4941, -1.9468,\n",
      "        -2.2322, -2.2318, -2.2313, -2.2313], requires_grad=True)\n",
      "Validation mae = 3.159546\n",
      "Epoch 33\n",
      "Loss = -3.6490e-01, PNorm = 26.8007, GNorm = 114.9237, lr_0 = 4.7147e-04, lr_1 = 4.7147e-04, lr_2 = 4.7147e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7783, -2.0676, -1.4925, -2.1241, -1.8330, -1.7137, -2.5207, -1.9749,\n",
      "        -2.2627, -2.2622, -2.2618, -2.2617], requires_grad=True)\n",
      "Validation mae = 3.449758\n",
      "Epoch 34\n",
      "Loss = -3.5429e-01, PNorm = 26.9871, GNorm = 71.5406, lr_0 = 4.6052e-04, lr_1 = 4.6052e-04, lr_2 = 4.6052e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7776, -2.0729, -1.4863, -2.1202, -1.8375, -1.7196, -2.5295, -1.9826,\n",
      "        -2.2673, -2.2667, -2.2664, -2.2662], requires_grad=True)\n",
      "Validation mae = 3.368750\n",
      "Epoch 35\n",
      "Loss = -3.5755e-01, PNorm = 27.0427, GNorm = 43.5200, lr_0 = 4.4983e-04, lr_1 = 4.4983e-04, lr_2 = 4.4983e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7809, -2.0791, -1.4993, -2.1362, -1.8490, -1.7265, -2.5388, -1.9880,\n",
      "        -2.2743, -2.2739, -2.2735, -2.2734], requires_grad=True)\n",
      "Validation mae = 3.223978\n",
      "Epoch 36\n",
      "Loss = -3.7143e-01, PNorm = 26.9282, GNorm = 62.6064, lr_0 = 4.3938e-04, lr_1 = 4.3938e-04, lr_2 = 4.3938e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7901, -2.1014, -1.5187, -2.1574, -1.8679, -1.7400, -2.5598, -2.0109,\n",
      "        -2.2979, -2.2974, -2.2971, -2.2968], requires_grad=True)\n",
      "Validation mae = 3.200518\n",
      "Epoch 37\n",
      "Loss = -3.6611e-01, PNorm = 26.9870, GNorm = 115.4221, lr_0 = 4.2918e-04, lr_1 = 4.2918e-04, lr_2 = 4.2918e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7966, -2.1115, -1.5228, -2.1447, -1.8657, -1.7482, -2.5728, -2.0212,\n",
      "        -2.3080, -2.3077, -2.3074, -2.3071], requires_grad=True)\n",
      "Validation mae = 3.754649\n",
      "Epoch 38\n",
      "Loss = -3.6554e-01, PNorm = 27.1103, GNorm = 42.6837, lr_0 = 4.1921e-04, lr_1 = 4.1921e-04, lr_2 = 4.1921e-04\n",
      "Parameter containing:\n",
      "tensor([-0.7934, -2.1185, -1.5284, -2.1445, -1.8675, -1.7555, -2.5849, -2.0268,\n",
      "        -2.3163, -2.3160, -2.3157, -2.3154], requires_grad=True)\n",
      "Validation mae = 3.143218\n",
      "Epoch 39\n",
      "Loss = -3.7422e-01, PNorm = 27.0397, GNorm = 91.2966, lr_0 = 4.0948e-04, lr_1 = 4.0948e-04, lr_2 = 4.0948e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8070, -2.1341, -1.5450, -2.1858, -1.8943, -1.7648, -2.5989, -2.0407,\n",
      "        -2.3313, -2.3311, -2.3308, -2.3306], requires_grad=True)\n",
      "Validation mae = 3.099974\n",
      "Epoch 40\n",
      "Loss = -3.8347e-01, PNorm = 27.0894, GNorm = 94.7247, lr_0 = 3.9997e-04, lr_1 = 3.9997e-04, lr_2 = 3.9997e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8128, -2.1538, -1.5486, -2.1965, -1.9050, -1.7758, -2.6182, -2.0597,\n",
      "        -2.3559, -2.3557, -2.3555, -2.3553], requires_grad=True)\n",
      "Validation mae = 3.312059\n",
      "Epoch 41\n",
      "Loss = -3.7370e-01, PNorm = 27.0839, GNorm = 44.2918, lr_0 = 3.9068e-04, lr_1 = 3.9068e-04, lr_2 = 3.9068e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8155, -2.1591, -1.5459, -2.1880, -1.9017, -1.7805, -2.6222, -2.0587,\n",
      "        -2.3611, -2.3609, -2.3606, -2.3604], requires_grad=True)\n",
      "Validation mae = 2.836060\n",
      "Epoch 42\n",
      "Loss = -3.9108e-01, PNorm = 26.9787, GNorm = 56.2142, lr_0 = 3.8161e-04, lr_1 = 3.8161e-04, lr_2 = 3.8161e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8212, -2.1810, -1.5740, -2.2213, -1.9323, -1.7968, -2.6447, -2.0824,\n",
      "        -2.3861, -2.3860, -2.3857, -2.3855], requires_grad=True)\n",
      "Validation mae = 3.300842\n",
      "Epoch 43\n",
      "Loss = -3.8736e-01, PNorm = 27.0632, GNorm = 100.5389, lr_0 = 3.7275e-04, lr_1 = 3.7275e-04, lr_2 = 3.7275e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8278, -2.1913, -1.5798, -2.2279, -1.9389, -1.8023, -2.6540, -2.0920,\n",
      "        -2.3993, -2.3992, -2.3989, -2.3987], requires_grad=True)\n",
      "Validation mae = 3.076523\n",
      "Epoch 44\n",
      "Loss = -3.8432e-01, PNorm = 27.1089, GNorm = 40.0155, lr_0 = 3.6409e-04, lr_1 = 3.6409e-04, lr_2 = 3.6409e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8334, -2.1973, -1.5886, -2.2399, -1.9459, -1.8078, -2.6605, -2.0973,\n",
      "        -2.4046, -2.4045, -2.4042, -2.4040], requires_grad=True)\n",
      "Validation mae = 2.848218\n",
      "Epoch 45\n",
      "Loss = -3.9785e-01, PNorm = 27.0795, GNorm = 113.1271, lr_0 = 3.5563e-04, lr_1 = 3.5563e-04, lr_2 = 3.5563e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8364, -2.2139, -1.5993, -2.2598, -1.9704, -1.8227, -2.6764, -2.1150,\n",
      "        -2.4254, -2.4253, -2.4251, -2.4248], requires_grad=True)\n",
      "Validation mae = 3.514592\n",
      "Epoch 46\n",
      "Loss = -3.9397e-01, PNorm = 27.1481, GNorm = 350.3901, lr_0 = 3.4738e-04, lr_1 = 3.4738e-04, lr_2 = 3.4738e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8456, -2.2244, -1.6138, -2.2670, -1.9754, -1.8288, -2.6865, -2.1254,\n",
      "        -2.4352, -2.4352, -2.4350, -2.4347], requires_grad=True)\n",
      "Validation mae = 3.040601\n",
      "Epoch 47\n",
      "Loss = -3.9865e-01, PNorm = 27.2229, GNorm = 250.3860, lr_0 = 3.3931e-04, lr_1 = 3.3931e-04, lr_2 = 3.3931e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8469, -2.2353, -1.6075, -2.2610, -1.9767, -1.8370, -2.6983, -2.1350,\n",
      "        -2.4498, -2.4497, -2.4496, -2.4492], requires_grad=True)\n",
      "Validation mae = 3.322195\n",
      "Epoch 48\n",
      "Loss = -3.9879e-01, PNorm = 27.2298, GNorm = 47.4917, lr_0 = 3.3143e-04, lr_1 = 3.3143e-04, lr_2 = 3.3143e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8523, -2.2427, -1.6285, -2.2831, -1.9990, -1.8416, -2.7076, -2.1418,\n",
      "        -2.4605, -2.4603, -2.4602, -2.4599], requires_grad=True)\n",
      "Validation mae = 2.810639\n",
      "Epoch 49\n",
      "Loss = -4.0303e-01, PNorm = 27.2569, GNorm = 79.7834, lr_0 = 3.2373e-04, lr_1 = 3.2373e-04, lr_2 = 3.2373e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8531, -2.2559, -1.6264, -2.2803, -1.9996, -1.8508, -2.7209, -2.1558,\n",
      "        -2.4731, -2.4730, -2.4728, -2.4725], requires_grad=True)\n",
      "Validation mae = 2.874042\n",
      "Epoch 50\n",
      "Loss = -4.1213e-01, PNorm = 27.2656, GNorm = 155.3651, lr_0 = 3.1622e-04, lr_1 = 3.1622e-04, lr_2 = 3.1622e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8602, -2.2698, -1.6368, -2.2908, -2.0128, -1.8618, -2.7353, -2.1697,\n",
      "        -2.4912, -2.4911, -2.4909, -2.4906], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mae = 2.985512\n",
      "Epoch 51\n",
      "Loss = -4.0177e-01, PNorm = 27.3235, GNorm = 44.9888, lr_0 = 3.0887e-04, lr_1 = 3.0887e-04, lr_2 = 3.0887e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8668, -2.2717, -1.6524, -2.3054, -2.0299, -1.8661, -2.7438, -2.1720,\n",
      "        -2.4967, -2.4966, -2.4964, -2.4961], requires_grad=True)\n",
      "Validation mae = 2.935012\n",
      "Epoch 52\n",
      "Loss = -4.2389e-01, PNorm = 27.3111, GNorm = 75.7853, lr_0 = 3.0170e-04, lr_1 = 3.0170e-04, lr_2 = 3.0170e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8751, -2.2896, -1.6673, -2.3241, -2.0451, -1.8766, -2.7590, -2.1882,\n",
      "        -2.5195, -2.5194, -2.5193, -2.5190], requires_grad=True)\n",
      "Validation mae = 3.132162\n",
      "Epoch 53\n",
      "Loss = -4.2266e-01, PNorm = 27.2690, GNorm = 99.5230, lr_0 = 2.9469e-04, lr_1 = 2.9469e-04, lr_2 = 2.9469e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8813, -2.3048, -1.6825, -2.3426, -2.0573, -1.8873, -2.7718, -2.2012,\n",
      "        -2.5377, -2.5376, -2.5376, -2.5373], requires_grad=True)\n",
      "Validation mae = 2.795774\n",
      "Epoch 54\n",
      "Loss = -4.1519e-01, PNorm = 27.2970, GNorm = 324.4106, lr_0 = 2.8785e-04, lr_1 = 2.8785e-04, lr_2 = 2.8785e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8882, -2.3129, -1.6885, -2.3522, -2.0704, -1.8934, -2.7789, -2.2072,\n",
      "        -2.5457, -2.5456, -2.5455, -2.5453], requires_grad=True)\n",
      "Validation mae = 2.923919\n",
      "Epoch 55\n",
      "Loss = -4.1778e-01, PNorm = 27.3636, GNorm = 77.5265, lr_0 = 2.8117e-04, lr_1 = 2.8117e-04, lr_2 = 2.8117e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8852, -2.3202, -1.6868, -2.3476, -2.0682, -1.8970, -2.7874, -2.2137,\n",
      "        -2.5537, -2.5536, -2.5535, -2.5533], requires_grad=True)\n",
      "Validation mae = 2.862529\n",
      "Epoch 56\n",
      "Loss = -4.3422e-01, PNorm = 27.2928, GNorm = 62.8248, lr_0 = 2.7464e-04, lr_1 = 2.7464e-04, lr_2 = 2.7464e-04\n",
      "Parameter containing:\n",
      "tensor([-0.8960, -2.3381, -1.7101, -2.3713, -2.0957, -1.9100, -2.8036, -2.2303,\n",
      "        -2.5731, -2.5730, -2.5730, -2.5727], requires_grad=True)\n",
      "Validation mae = 2.869243\n",
      "Epoch 57\n",
      "Loss = -4.3636e-01, PNorm = 27.2650, GNorm = 80.4778, lr_0 = 2.6826e-04, lr_1 = 2.6826e-04, lr_2 = 2.6826e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9032, -2.3513, -1.7165, -2.3849, -2.1070, -1.9206, -2.8145, -2.2432,\n",
      "        -2.5897, -2.5896, -2.5895, -2.5894], requires_grad=True)\n",
      "Validation mae = 2.705477\n",
      "Epoch 58\n",
      "Loss = -4.2860e-01, PNorm = 27.3022, GNorm = 83.0107, lr_0 = 2.6203e-04, lr_1 = 2.6203e-04, lr_2 = 2.6203e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9036, -2.3586, -1.7240, -2.3781, -2.1060, -1.9286, -2.8218, -2.2509,\n",
      "        -2.5997, -2.5996, -2.5996, -2.5994], requires_grad=True)\n",
      "Validation mae = 2.775159\n",
      "Epoch 59\n",
      "Loss = -4.3943e-01, PNorm = 27.2886, GNorm = 110.0032, lr_0 = 2.5595e-04, lr_1 = 2.5595e-04, lr_2 = 2.5595e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9090, -2.3710, -1.7336, -2.4031, -2.1239, -1.9385, -2.8332, -2.2641,\n",
      "        -2.6145, -2.6145, -2.6144, -2.6142], requires_grad=True)\n",
      "Validation mae = 2.719493\n",
      "Epoch 60\n",
      "Loss = -4.3594e-01, PNorm = 27.2972, GNorm = 79.5851, lr_0 = 2.5000e-04, lr_1 = 2.5000e-04, lr_2 = 2.5000e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9155, -2.3799, -1.7484, -2.4164, -2.1390, -1.9463, -2.8417, -2.2720,\n",
      "        -2.6244, -2.6244, -2.6243, -2.6241], requires_grad=True)\n",
      "Validation mae = 2.827799\n",
      "Epoch 61\n",
      "Loss = -4.4414e-01, PNorm = 27.2509, GNorm = 232.2515, lr_0 = 2.4420e-04, lr_1 = 2.4420e-04, lr_2 = 2.4420e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9234, -2.3934, -1.7606, -2.4315, -2.1586, -1.9552, -2.8525, -2.2840,\n",
      "        -2.6378, -2.6377, -2.6377, -2.6375], requires_grad=True)\n",
      "Validation mae = 2.659287\n",
      "Epoch 62\n",
      "Loss = -4.5173e-01, PNorm = 27.2028, GNorm = 67.0714, lr_0 = 2.3853e-04, lr_1 = 2.3853e-04, lr_2 = 2.3853e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9281, -2.4066, -1.7774, -2.4403, -2.1697, -1.9664, -2.8647, -2.2981,\n",
      "        -2.6552, -2.6551, -2.6551, -2.6549], requires_grad=True)\n",
      "Validation mae = 2.628022\n",
      "Epoch 63\n",
      "Loss = -4.5112e-01, PNorm = 27.2049, GNorm = 96.9462, lr_0 = 2.3299e-04, lr_1 = 2.3299e-04, lr_2 = 2.3299e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9293, -2.4180, -1.7834, -2.4467, -2.1796, -1.9757, -2.8744, -2.3080,\n",
      "        -2.6699, -2.6698, -2.6698, -2.6697], requires_grad=True)\n",
      "Validation mae = 2.641658\n",
      "Epoch 64\n",
      "Loss = -4.4536e-01, PNorm = 27.2505, GNorm = 60.9836, lr_0 = 2.2758e-04, lr_1 = 2.2758e-04, lr_2 = 2.2758e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9348, -2.4241, -1.7848, -2.4515, -2.1862, -1.9810, -2.8795, -2.3137,\n",
      "        -2.6797, -2.6796, -2.6797, -2.6795], requires_grad=True)\n",
      "Validation mae = 2.793029\n",
      "Epoch 65\n",
      "Loss = -4.5191e-01, PNorm = 27.2426, GNorm = 69.2045, lr_0 = 2.2229e-04, lr_1 = 2.2229e-04, lr_2 = 2.2229e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9401, -2.4339, -1.8004, -2.4661, -2.2050, -1.9876, -2.8894, -2.3222,\n",
      "        -2.6911, -2.6910, -2.6911, -2.6909], requires_grad=True)\n",
      "Validation mae = 2.769358\n",
      "Epoch 66\n",
      "Loss = -4.3651e-01, PNorm = 27.3573, GNorm = 157.7736, lr_0 = 2.1713e-04, lr_1 = 2.1713e-04, lr_2 = 2.1713e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9415, -2.4350, -1.7978, -2.4604, -2.2001, -1.9924, -2.8914, -2.3241,\n",
      "        -2.6908, -2.6908, -2.6908, -2.6906], requires_grad=True)\n",
      "Validation mae = 2.734964\n",
      "Epoch 67\n",
      "Loss = -4.5584e-01, PNorm = 27.3273, GNorm = 65.3675, lr_0 = 2.1209e-04, lr_1 = 2.1209e-04, lr_2 = 2.1209e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9448, -2.4444, -1.8119, -2.4826, -2.2215, -1.9990, -2.8999, -2.3323,\n",
      "        -2.6998, -2.6997, -2.6997, -2.6995], requires_grad=True)\n",
      "Validation mae = 2.669990\n",
      "Epoch 68\n",
      "Loss = -4.5961e-01, PNorm = 27.3139, GNorm = 145.0955, lr_0 = 2.0716e-04, lr_1 = 2.0716e-04, lr_2 = 2.0716e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9525, -2.4527, -1.8249, -2.4923, -2.2352, -2.0081, -2.9076, -2.3405,\n",
      "        -2.7095, -2.7094, -2.7094, -2.7092], requires_grad=True)\n",
      "Validation mae = 2.733334\n",
      "Epoch 69\n",
      "Loss = -4.6155e-01, PNorm = 27.2914, GNorm = 65.2186, lr_0 = 2.0235e-04, lr_1 = 2.0235e-04, lr_2 = 2.0235e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9596, -2.4614, -1.8396, -2.5089, -2.2527, -2.0205, -2.9160, -2.3498,\n",
      "        -2.7192, -2.7191, -2.7191, -2.7189], requires_grad=True)\n",
      "Validation mae = 2.785899\n",
      "Epoch 70\n",
      "Loss = -4.6314e-01, PNorm = 27.2722, GNorm = 95.1980, lr_0 = 1.9765e-04, lr_1 = 1.9765e-04, lr_2 = 1.9765e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9643, -2.4708, -1.8532, -2.5210, -2.2677, -2.0251, -2.9231, -2.3568,\n",
      "        -2.7290, -2.7289, -2.7289, -2.7287], requires_grad=True)\n",
      "Validation mae = 2.725231\n",
      "Epoch 71\n",
      "Loss = -4.6277e-01, PNorm = 27.2949, GNorm = 163.1132, lr_0 = 1.9306e-04, lr_1 = 1.9306e-04, lr_2 = 1.9306e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9669, -2.4771, -1.8594, -2.5276, -2.2728, -2.0313, -2.9287, -2.3625,\n",
      "        -2.7369, -2.7369, -2.7369, -2.7367], requires_grad=True)\n",
      "Validation mae = 2.549191\n",
      "Epoch 72\n",
      "Loss = -4.6716e-01, PNorm = 27.2723, GNorm = 62.4621, lr_0 = 1.8858e-04, lr_1 = 1.8858e-04, lr_2 = 1.8858e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9703, -2.4841, -1.8733, -2.5407, -2.2883, -2.0373, -2.9350, -2.3692,\n",
      "        -2.7456, -2.7456, -2.7456, -2.7454], requires_grad=True)\n",
      "Validation mae = 2.683775\n",
      "Epoch 73\n",
      "Loss = -4.6989e-01, PNorm = 27.2380, GNorm = 97.4192, lr_0 = 1.8420e-04, lr_1 = 1.8420e-04, lr_2 = 1.8420e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9771, -2.4912, -1.8819, -2.5542, -2.3025, -2.0447, -2.9413, -2.3761,\n",
      "        -2.7539, -2.7539, -2.7539, -2.7537], requires_grad=True)\n",
      "Validation mae = 2.469151\n",
      "Epoch 74\n",
      "Loss = -4.7015e-01, PNorm = 27.2479, GNorm = 120.4560, lr_0 = 1.7992e-04, lr_1 = 1.7992e-04, lr_2 = 1.7992e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9802, -2.4994, -1.8872, -2.5669, -2.3136, -2.0511, -2.9488, -2.3838,\n",
      "        -2.7626, -2.7626, -2.7626, -2.7624], requires_grad=True)\n",
      "Validation mae = 2.759051\n",
      "Epoch 75\n",
      "Loss = -4.6819e-01, PNorm = 27.2891, GNorm = 64.6029, lr_0 = 1.7574e-04, lr_1 = 1.7574e-04, lr_2 = 1.7574e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9819, -2.5036, -1.8954, -2.5721, -2.3199, -2.0555, -2.9529, -2.3880,\n",
      "        -2.7686, -2.7686, -2.7686, -2.7685], requires_grad=True)\n",
      "Validation mae = 2.501086\n",
      "Epoch 76\n",
      "Loss = -4.7329e-01, PNorm = 27.2977, GNorm = 134.3189, lr_0 = 1.7166e-04, lr_1 = 1.7166e-04, lr_2 = 1.7166e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9886, -2.5100, -1.9070, -2.5830, -2.3324, -2.0618, -2.9580, -2.3941,\n",
      "        -2.7758, -2.7757, -2.7758, -2.7756], requires_grad=True)\n",
      "Validation mae = 2.548275\n",
      "Epoch 77\n",
      "Loss = -4.7019e-01, PNorm = 27.3031, GNorm = 120.4208, lr_0 = 1.6768e-04, lr_1 = 1.6768e-04, lr_2 = 1.6768e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9914, -2.5165, -1.9179, -2.5913, -2.3456, -2.0681, -2.9637, -2.4006,\n",
      "        -2.7809, -2.7809, -2.7809, -2.7807], requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mae = 2.658275\n",
      "Epoch 78\n",
      "Loss = -4.7511e-01, PNorm = 27.2950, GNorm = 79.9496, lr_0 = 1.6378e-04, lr_1 = 1.6378e-04, lr_2 = 1.6378e-04\n",
      "Parameter containing:\n",
      "tensor([-0.9967, -2.5206, -1.9281, -2.6003, -2.3556, -2.0758, -2.9673, -2.4052,\n",
      "        -2.7859, -2.7859, -2.7859, -2.7857], requires_grad=True)\n",
      "Validation mae = 2.535998\n",
      "Epoch 79\n",
      "Loss = -4.7867e-01, PNorm = 27.2811, GNorm = 95.4715, lr_0 = 1.5998e-04, lr_1 = 1.5998e-04, lr_2 = 1.5998e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0019, -2.5263, -1.9409, -2.6121, -2.3712, -2.0831, -2.9726, -2.4113,\n",
      "        -2.7923, -2.7923, -2.7923, -2.7922], requires_grad=True)\n",
      "Validation mae = 2.569717\n",
      "Epoch 80\n",
      "Loss = -4.8160e-01, PNorm = 27.2778, GNorm = 75.1990, lr_0 = 1.5626e-04, lr_1 = 1.5626e-04, lr_2 = 1.5626e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0047, -2.5323, -1.9488, -2.6241, -2.3833, -2.0898, -2.9779, -2.4173,\n",
      "        -2.7990, -2.7990, -2.7990, -2.7988], requires_grad=True)\n",
      "Validation mae = 2.513182\n",
      "Epoch 81\n",
      "Loss = -4.7210e-01, PNorm = 27.2829, GNorm = 98.7786, lr_0 = 1.5264e-04, lr_1 = 1.5264e-04, lr_2 = 1.5264e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0077, -2.5349, -1.9578, -2.6310, -2.3955, -2.0948, -2.9797, -2.4189,\n",
      "        -2.8026, -2.8026, -2.8026, -2.8024], requires_grad=True)\n",
      "Validation mae = 2.559852\n",
      "Epoch 82\n",
      "Loss = -4.8201e-01, PNorm = 27.2778, GNorm = 120.0758, lr_0 = 1.4909e-04, lr_1 = 1.4909e-04, lr_2 = 1.4909e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0108, -2.5387, -1.9665, -2.6402, -2.4038, -2.1013, -2.9829, -2.4228,\n",
      "        -2.8074, -2.8074, -2.8074, -2.8073], requires_grad=True)\n",
      "Validation mae = 2.609491\n",
      "Epoch 83\n",
      "Loss = -4.8562e-01, PNorm = 27.2615, GNorm = 84.3907, lr_0 = 1.4563e-04, lr_1 = 1.4563e-04, lr_2 = 1.4563e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0154, -2.5445, -1.9761, -2.6521, -2.4158, -2.1082, -2.9879, -2.4284,\n",
      "        -2.8136, -2.8136, -2.8136, -2.8134], requires_grad=True)\n",
      "Validation mae = 2.553488\n",
      "Epoch 84\n",
      "Loss = -4.8598e-01, PNorm = 27.2466, GNorm = 120.0677, lr_0 = 1.4225e-04, lr_1 = 1.4225e-04, lr_2 = 1.4225e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0207, -2.5490, -1.9881, -2.6615, -2.4267, -2.1156, -2.9914, -2.4330,\n",
      "        -2.8187, -2.8187, -2.8187, -2.8186], requires_grad=True)\n",
      "Validation mae = 2.591313\n",
      "Epoch 85\n",
      "Loss = -4.8816e-01, PNorm = 27.2309, GNorm = 111.0013, lr_0 = 1.3894e-04, lr_1 = 1.3894e-04, lr_2 = 1.3894e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0255, -2.5541, -1.9991, -2.6721, -2.4388, -2.1222, -2.9956, -2.4377,\n",
      "        -2.8245, -2.8245, -2.8245, -2.8243], requires_grad=True)\n",
      "Validation mae = 2.602167\n",
      "Epoch 86\n",
      "Loss = -4.8707e-01, PNorm = 27.2547, GNorm = 69.1195, lr_0 = 1.3572e-04, lr_1 = 1.3572e-04, lr_2 = 1.3572e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0284, -2.5580, -2.0065, -2.6794, -2.4470, -2.1291, -2.9987, -2.4417,\n",
      "        -2.8282, -2.8282, -2.8283, -2.8281], requires_grad=True)\n",
      "Validation mae = 2.495105\n",
      "Epoch 87\n",
      "Loss = -4.8759e-01, PNorm = 27.2890, GNorm = 144.0032, lr_0 = 1.3257e-04, lr_1 = 1.3257e-04, lr_2 = 1.3257e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0290, -2.5625, -2.0121, -2.6858, -2.4551, -2.1349, -3.0025, -2.4461,\n",
      "        -2.8327, -2.8327, -2.8327, -2.8325], requires_grad=True)\n",
      "Validation mae = 2.495551\n",
      "Epoch 88\n",
      "Loss = -4.8932e-01, PNorm = 27.2750, GNorm = 97.4319, lr_0 = 1.2949e-04, lr_1 = 1.2949e-04, lr_2 = 1.2949e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0336, -2.5670, -2.0191, -2.6945, -2.4676, -2.1412, -3.0060, -2.4501,\n",
      "        -2.8364, -2.8364, -2.8365, -2.8363], requires_grad=True)\n",
      "Validation mae = 2.489259\n",
      "Epoch 89\n",
      "Loss = -4.8725e-01, PNorm = 27.3122, GNorm = 118.3554, lr_0 = 1.2648e-04, lr_1 = 1.2648e-04, lr_2 = 1.2648e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0348, -2.5704, -2.0247, -2.6983, -2.4741, -2.1456, -3.0092, -2.4533,\n",
      "        -2.8398, -2.8398, -2.8398, -2.8396], requires_grad=True)\n",
      "Validation mae = 2.587960\n",
      "Epoch 90\n",
      "Loss = -4.8815e-01, PNorm = 27.3071, GNorm = 104.5875, lr_0 = 1.2354e-04, lr_1 = 1.2354e-04, lr_2 = 1.2354e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0382, -2.5730, -2.0333, -2.7073, -2.4818, -2.1517, -3.0123, -2.4559,\n",
      "        -2.8426, -2.8426, -2.8426, -2.8425], requires_grad=True)\n",
      "Validation mae = 2.425389\n",
      "Epoch 91\n",
      "Loss = -4.9543e-01, PNorm = 27.2987, GNorm = 81.7143, lr_0 = 1.2067e-04, lr_1 = 1.2067e-04, lr_2 = 1.2067e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0424, -2.5778, -2.0450, -2.7199, -2.4974, -2.1588, -3.0161, -2.4606,\n",
      "        -2.8470, -2.8470, -2.8470, -2.8469], requires_grad=True)\n",
      "Validation mae = 2.563615\n",
      "Epoch 92\n",
      "Loss = -4.9561e-01, PNorm = 27.3055, GNorm = 94.4554, lr_0 = 1.1787e-04, lr_1 = 1.1787e-04, lr_2 = 1.1787e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0457, -2.5816, -2.0524, -2.7305, -2.5070, -2.1656, -3.0192, -2.4646,\n",
      "        -2.8509, -2.8509, -2.8509, -2.8508], requires_grad=True)\n",
      "Validation mae = 2.525018\n",
      "Epoch 93\n",
      "Loss = -4.9832e-01, PNorm = 27.3008, GNorm = 135.6420, lr_0 = 1.1514e-04, lr_1 = 1.1514e-04, lr_2 = 1.1514e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0500, -2.5857, -2.0621, -2.7436, -2.5204, -2.1743, -3.0224, -2.4689,\n",
      "        -2.8551, -2.8551, -2.8551, -2.8549], requires_grad=True)\n",
      "Validation mae = 2.905435\n",
      "Epoch 94\n",
      "Loss = -4.9991e-01, PNorm = 27.2957, GNorm = 78.4499, lr_0 = 1.1246e-04, lr_1 = 1.1246e-04, lr_2 = 1.1246e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0533, -2.5899, -2.0719, -2.7533, -2.5308, -2.1809, -3.0257, -2.4732,\n",
      "        -2.8591, -2.8591, -2.8591, -2.8589], requires_grad=True)\n",
      "Validation mae = 2.722923\n",
      "Epoch 95\n",
      "Loss = -4.9933e-01, PNorm = 27.2980, GNorm = 62.3363, lr_0 = 1.0985e-04, lr_1 = 1.0985e-04, lr_2 = 1.0985e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0564, -2.5946, -2.0808, -2.7595, -2.5381, -2.1874, -3.0296, -2.4777,\n",
      "        -2.8633, -2.8633, -2.8634, -2.8632], requires_grad=True)\n",
      "Validation mae = 2.488600\n",
      "Epoch 96\n",
      "Loss = -5.0107e-01, PNorm = 27.2989, GNorm = 133.4421, lr_0 = 1.0730e-04, lr_1 = 1.0730e-04, lr_2 = 1.0730e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0598, -2.5974, -2.0882, -2.7683, -2.5481, -2.1941, -3.0315, -2.4805,\n",
      "        -2.8662, -2.8662, -2.8663, -2.8661], requires_grad=True)\n",
      "Validation mae = 2.495893\n",
      "Epoch 97\n",
      "Loss = -5.0196e-01, PNorm = 27.2912, GNorm = 147.4738, lr_0 = 1.0481e-04, lr_1 = 1.0481e-04, lr_2 = 1.0481e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0621, -2.6013, -2.0979, -2.7764, -2.5586, -2.1999, -3.0348, -2.4847,\n",
      "        -2.8702, -2.8702, -2.8702, -2.8701], requires_grad=True)\n",
      "Validation mae = 2.602330\n",
      "Epoch 98\n",
      "Loss = -5.0225e-01, PNorm = 27.3056, GNorm = 92.5520, lr_0 = 1.0237e-04, lr_1 = 1.0237e-04, lr_2 = 1.0237e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0652, -2.6048, -2.1037, -2.7823, -2.5655, -2.2061, -3.0375, -2.4881,\n",
      "        -2.8735, -2.8735, -2.8736, -2.8734], requires_grad=True)\n",
      "Validation mae = 2.560625\n",
      "Epoch 99\n",
      "Loss = -5.0207e-01, PNorm = 27.3119, GNorm = 120.1412, lr_0 = 1.0000e-04, lr_1 = 1.0000e-04, lr_2 = 1.0000e-04\n",
      "Parameter containing:\n",
      "tensor([-1.0682, -2.6073, -2.1105, -2.7879, -2.5723, -2.2112, -3.0394, -2.4906,\n",
      "        -2.8761, -2.8761, -2.8761, -2.8759], requires_grad=True)\n",
      "Validation mae = 2.694836\n",
      "Model 0 best validation mae = 2.425389 on epoch 90\n",
      "Model 0, sample 0 test mae = 2.457753\n",
      "BMA test mae = 2.457753\n"
     ]
    }
   ],
   "source": [
    "args.weight_decay = 0.01\n",
    "results_MAP = run_training(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
