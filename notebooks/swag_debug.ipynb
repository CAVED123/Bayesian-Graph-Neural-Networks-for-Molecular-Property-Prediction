{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "from logging import Logger\n",
    "from typing import List\n",
    "from tqdm import trange\n",
    "\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/georgelamb/Documents/GitHub/chempropBayes\n"
     ]
    }
   ],
   "source": [
    "# cd to chempropBayes\n",
    "%cd /Users/georgelamb/Documents/GitHub/chempropBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from chempropBayes\n",
    "from chemprop.train.evaluate import evaluate, evaluate_predictions\n",
    "from chemprop.train.predict import predict\n",
    "from chemprop.train.train import train\n",
    "from chemprop.train.run_training import run_training\n",
    "from chemprop.args import TrainArgs, HyperoptArgs\n",
    "from chemprop.data import StandardScaler, MoleculeDataLoader\n",
    "from chemprop.data.utils import get_class_sizes, get_data, get_task_names, split_data\n",
    "from chemprop.models import MoleculeModel\n",
    "from chemprop.nn_utils import param_count\n",
    "from chemprop.utils import build_optimizer, build_lr_scheduler, get_loss_func, get_metric_func, load_checkpoint,\\\n",
    "    makedirs, save_checkpoint, save_smiles_splits\n",
    "from chemprop.bayes_utils import flatten, unflatten_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate args class and load from dict\n",
    "args = TrainArgs()\n",
    "args.from_dict({\n",
    "    'dataset_type': 'regression',\n",
    "    'data_path': '/Users/georgelamb/Documents/GitHub/chempropBayes/data/QM9.csv'\n",
    "})\n",
    "\n",
    "# location for model checkpoints to be saved\n",
    "args.save_dir = '/Users/georgelamb/Documents/GitHub/chempropBayes/log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### args (non-model)\n",
    "\n",
    "# seed for splitting and loading data\n",
    "args.seed = 0\n",
    "\n",
    "# data\n",
    "args.max_data_size = 50000\n",
    "args.features_path = None\n",
    "args.features_generator = None\n",
    "\n",
    "# splitting data\n",
    "args.split_type = 'random'\n",
    "args.split_sizes = (0.8, 0.1, 0.1)\n",
    "\n",
    "# evaluation metric\n",
    "args.metric = 'mae'\n",
    "\n",
    "# epochs and logging\n",
    "args.epochs = 50\n",
    "args.log_frequency = 800\n",
    "\n",
    "### args (model)\n",
    "\n",
    "# seed for random initial weights\n",
    "args.pytorch_seed = 0\n",
    "\n",
    "# message passing\n",
    "args.atom_messages = False\n",
    "args.undirected = False\n",
    "args.bias = False\n",
    "args.hidden_size = 500\n",
    "args.depth = 5\n",
    "\n",
    "# FFN\n",
    "args.ffn_hidden_size = args.hidden_size\n",
    "args.ffn_num_layers = 3\n",
    "\n",
    "# shared\n",
    "args.activation = 'ReLU'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUGUST DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig model\n",
    "args.num_tasks = 12\n",
    "model = MoleculeModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[-0.0102,  0.0087, -0.0803,  ...,  0.0164,  0.1021, -0.0389],\n",
      "        [ 0.0828,  0.0034,  0.0594,  ...,  0.0319, -0.0188,  0.0197],\n",
      "        [ 0.0066,  0.0641, -0.0326,  ...,  0.0310, -0.0521, -0.0345],\n",
      "        ...,\n",
      "        [-0.0175, -0.0442, -0.0165,  ..., -0.0742, -0.0418,  0.0241],\n",
      "        [-0.0454,  0.0140, -0.0222,  ..., -0.0429,  0.1009, -0.0187],\n",
      "        [-0.0807,  0.1306, -0.0994,  ...,  0.0380, -0.0689,  0.0644]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0155,  0.0132, -0.0207,  ..., -0.0640, -0.0218, -0.0281],\n",
      "        [ 0.0396, -0.0673, -0.0014,  ...,  0.0423,  0.0602, -0.0336],\n",
      "        [-0.0274, -0.0017, -0.0002,  ...,  0.0102,  0.0237, -0.0010],\n",
      "        ...,\n",
      "        [-0.0330, -0.0519,  0.0121,  ..., -0.0667, -0.0359,  0.0093],\n",
      "        [-0.0485,  0.0470,  0.0124,  ...,  0.0510,  0.0315,  0.0005],\n",
      "        [-0.0777,  0.0213, -0.0591,  ..., -0.0126, -0.0454, -0.0145]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0286, -0.0506,  0.0310,  ..., -0.0602,  0.0425,  0.0485],\n",
      "        [-0.0236,  0.0254,  0.0632,  ..., -0.0305, -0.0390,  0.0677],\n",
      "        [ 0.0009, -0.0211,  0.0154,  ...,  0.0128,  0.0340,  0.0483],\n",
      "        ...,\n",
      "        [ 0.0474, -0.0080,  0.0133,  ...,  0.0203,  0.0159, -0.0158],\n",
      "        [ 0.0280,  0.0043,  0.0088,  ...,  0.0305, -0.0754, -0.0430],\n",
      "        [-0.0414,  0.0080,  0.0251,  ..., -0.0284, -0.0197, -0.0534]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0966, -0.1350, -0.0337,  ...,  0.0325, -0.0094,  0.0003],\n",
      "        [-0.0287,  0.0260, -0.0108,  ..., -0.0333, -0.0112,  0.0133],\n",
      "        [-0.0546, -0.0075, -0.0212,  ..., -0.0756,  0.1431, -0.0007],\n",
      "        ...,\n",
      "        [-0.0413, -0.0365,  0.0232,  ...,  0.0079, -0.0041, -0.0096],\n",
      "        [-0.0011,  0.0454, -0.0161,  ..., -0.0569, -0.0248,  0.1030],\n",
      "        [-0.0066,  0.0186, -0.0419,  ..., -0.0017,  0.0342, -0.0081]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0200,  0.0050,  0.0180,  ..., -0.0726,  0.0405,  0.0533],\n",
      "        [ 0.0118,  0.0343, -0.0231,  ..., -0.0584,  0.0533, -0.1053],\n",
      "        [ 0.0096, -0.0272,  0.0673,  ..., -0.0163,  0.0315, -0.0671],\n",
      "        ...,\n",
      "        [ 0.0698, -0.0823, -0.0313,  ...,  0.0299, -0.0419, -0.0080],\n",
      "        [-0.0137, -0.0653,  0.0755,  ..., -0.0079,  0.0762, -0.0055],\n",
      "        [ 0.0116, -0.0691, -0.1318,  ..., -0.0041,  0.0125, -0.0329]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1066,  0.0552,  0.0870,  ...,  0.0062,  0.0380, -0.0297],\n",
      "        [-0.0467, -0.0852,  0.0391,  ..., -0.1220, -0.0533, -0.0798],\n",
      "        [ 0.0760, -0.0659, -0.0067,  ..., -0.0371, -0.1061,  0.1031],\n",
      "        ...,\n",
      "        [-0.0385,  0.0672, -0.0373,  ..., -0.0422, -0.0454,  0.0778],\n",
      "        [ 0.0631,  0.0229, -0.1034,  ..., -0.0087, -0.0216,  0.1289],\n",
      "        [-0.0548, -0.1768,  0.0051,  ...,  0.0835, -0.0283,  0.0005]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for base_param in model.parameters():\n",
    "    print(base_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['weight', 'bias']\n",
      "['weight', 'bias']\n",
      "['weight', 'bias']\n",
      "['cached_zero_vector']\n",
      "[]\n",
      "[]\n",
      "['weight', 'bias']\n",
      "[]\n",
      "['weight', 'bias']\n",
      "['weight', 'bias']\n",
      "[]\n",
      "['log_noise']\n"
     ]
    }
   ],
   "source": [
    "swag_model = SWAG(\n",
    "    model,\n",
    "    no_cov_mat=True,\n",
    "    max_num_models=12,\n",
    "    var_clamp=1e-30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(MoleculeModel(\n",
       "    (encoder): MPN(\n",
       "      (encoder): MPNEncoder(\n",
       "        (dropout_layer): Dropout(p=0, inplace=False)\n",
       "        (act_func): ReLU()\n",
       "        (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
       "        (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
       "        (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): Dropout(p=0, inplace=False)\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0, inplace=False)\n",
       "      (4): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Dropout(p=0, inplace=False)\n",
       "      (7): Linear(in_features=500, out_features=12, bias=True)\n",
       "    )\n",
       "  ),\n",
       "  'log_noise'),\n",
       " (MPNEncoder(\n",
       "    (dropout_layer): Dropout(p=0, inplace=False)\n",
       "    (act_func): ReLU()\n",
       "    (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
       "    (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
       "    (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
       "  ),\n",
       "  'cached_zero_vector'),\n",
       " (Linear(in_features=147, out_features=500, bias=False), 'weight'),\n",
       " (Linear(in_features=500, out_features=500, bias=False), 'weight'),\n",
       " (Linear(in_features=633, out_features=500, bias=True), 'weight'),\n",
       " (Linear(in_features=633, out_features=500, bias=True), 'bias'),\n",
       " (Linear(in_features=500, out_features=500, bias=True), 'weight'),\n",
       " (Linear(in_features=500, out_features=500, bias=True), 'bias'),\n",
       " (Linear(in_features=500, out_features=500, bias=True), 'weight'),\n",
       " (Linear(in_features=500, out_features=500, bias=True), 'bias'),\n",
       " (Linear(in_features=500, out_features=12, bias=True), 'weight'),\n",
       " (Linear(in_features=500, out_features=12, bias=True), 'bias')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag_model.sample()\n",
    "swag_model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swag_parameters(module, params, no_cov_mat=True):\n",
    "    \"\"\"\n",
    "    module: submodule of base model\n",
    "    params: list of params\n",
    "    no_cov_mat: True means SWAG DIAG\n",
    "    \"\"\"\n",
    "    print(list(module._parameters.keys()))\n",
    "    for name in list(module._parameters.keys()):\n",
    "        #print(name)\n",
    "        if module._parameters[name] is None:\n",
    "            continue\n",
    "        data = module._parameters[name].data\n",
    "        module._parameters.pop(name)\n",
    "        \n",
    "        # registers buffers for first moment and second moment\n",
    "        # initialised at zero?\n",
    "        module.register_buffer(\"%s_mean\" % name, data.new(data.size()).zero_())\n",
    "        module.register_buffer(\"%s_sq_mean\" % name, data.new(data.size()).zero_())\n",
    "        \n",
    "        # if full SWAG, registers D (sqrt of covariance matrix)\n",
    "        if no_cov_mat is False:\n",
    "            module.register_buffer(\n",
    "                \"%s_cov_mat_sqrt\" % name, data.new_empty((0, data.numel())).zero_()\n",
    "            )\n",
    "\n",
    "        # append to list of SWAG parameters\n",
    "        # HAVE INSERTED A HACK HERE TO COPE WITH CACHED_ZERO_VECTOR\n",
    "        if name == 'cached_zero_vector' or name == 'log_noise':\n",
    "            params.insert(0,(module, name))    \n",
    "        else:\n",
    "            params.append((module, name))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class SWAG(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SWAG module which builds upon a base NN module\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base, no_cov_mat=True, max_num_models=0, var_clamp=1e-30):\n",
    "        super(SWAG, self).__init__()\n",
    "\n",
    "        # adds buffer to module, counting number of models\n",
    "        self.register_buffer(\"n_models\", torch.zeros([1], dtype=torch.long))\n",
    "        \n",
    "        # empty list\n",
    "        self.params = list()\n",
    "\n",
    "        self.no_cov_mat = no_cov_mat\n",
    "        self.max_num_models = max_num_models\n",
    "        self.var_clamp = var_clamp\n",
    "\n",
    "        # deepcopy of base model\n",
    "        self.base = copy.deepcopy(base)\n",
    "        \n",
    "        # applies swag_parameters function to each submodule of base (loop over submodules is implicit)\n",
    "        self.base.apply(\n",
    "            lambda module: swag_parameters(\n",
    "                module=module, params=self.params, no_cov_mat=self.no_cov_mat\n",
    "            )\n",
    "        )\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, *input):\n",
    "        return self.base(*input)\n",
    "\n",
    "\n",
    "\n",
    "    def sample(self, scale=1.0, cov=False, seed=None, block=False, fullrank=True):\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        if not block:\n",
    "            self.sample_fullrank(scale, cov, fullrank)\n",
    "        else:\n",
    "            self.sample_blockwise(scale, cov, fullrank)\n",
    "\n",
    "\n",
    "\n",
    "    def sample_blockwise(self, scale, cov, fullrank):\n",
    "        \"\"\"\n",
    "        samples blockwise: assumes at most covariance within each module\n",
    "        \"\"\"\n",
    "        \n",
    "        # self.params is a list of submodules and names\n",
    "        for module, name in self.params:\n",
    "            \n",
    "            # first moment\n",
    "            mean = module.__getattr__(\"%s_mean\" % name)\n",
    "            \n",
    "            # second moment\n",
    "            sq_mean = module.__getattr__(\"%s_sq_mean\" % name)\n",
    "            \n",
    "            # random numbers from normal distribution with mean zero and variance 1            \n",
    "            eps = torch.randn_like(mean)\n",
    "\n",
    "            # variance for each parameter\n",
    "            var = torch.clamp(sq_mean - mean ** 2, self.var_clamp)\n",
    "\n",
    "            # produce a sample from the diagonal variance (scaled)\n",
    "            scaled_diag_sample = scale * torch.sqrt(var) * eps\n",
    "\n",
    "            # if we have covariance...\n",
    "            if cov is True:\n",
    "                \n",
    "                # get our D matrix\n",
    "                cov_mat_sqrt = module.__getattr__(\"%s_cov_mat_sqrt\" % name)\n",
    "                \n",
    "                # new tensor: number of weights X 1, normally distributed\n",
    "                eps = cov_mat_sqrt.new_empty((cov_mat_sqrt.size(0), 1)).normal_()\n",
    "                \n",
    "                # cov sample\n",
    "                cov_sample = (\n",
    "                    scale / ((self.max_num_models - 1) ** 0.5)\n",
    "                ) * cov_mat_sqrt.t().matmul(eps).view_as(mean)\n",
    "\n",
    "                if fullrank:\n",
    "                    w = mean + scaled_diag_sample + cov_sample\n",
    "                else:\n",
    "                    w = mean + scaled_diag_sample\n",
    "\n",
    "            else:\n",
    "                w = mean + scaled_diag_sample\n",
    "\n",
    "            module.__setattr__(name, w)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def sample_fullrank(self, scale, cov, fullrank):\n",
    "        \"\"\"\n",
    "        samples fullrank: assumes covariance between submodules\n",
    "        \"\"\"\n",
    "        scale_sqrt = scale ** 0.5\n",
    "\n",
    "        mean_list = []\n",
    "        sq_mean_list = []\n",
    "\n",
    "        if cov:\n",
    "            cov_mat_sqrt_list = []\n",
    "\n",
    "        for (module, name) in self.params:\n",
    "            mean = module.__getattr__(\"%s_mean\" % name)\n",
    "            sq_mean = module.__getattr__(\"%s_sq_mean\" % name)\n",
    "\n",
    "            if cov:\n",
    "                cov_mat_sqrt = module.__getattr__(\"%s_cov_mat_sqrt\" % name)\n",
    "                cov_mat_sqrt_list.append(cov_mat_sqrt.cpu())\n",
    "\n",
    "            mean_list.append(mean.cpu())\n",
    "            sq_mean_list.append(sq_mean.cpu())\n",
    "\n",
    "        mean = flatten(mean_list)\n",
    "        sq_mean = flatten(sq_mean_list)\n",
    "\n",
    "        # draw diagonal variance sample\n",
    "        var = torch.clamp(sq_mean - mean ** 2, self.var_clamp)\n",
    "        var_sample = var.sqrt() * torch.randn_like(var, requires_grad=False)\n",
    "\n",
    "        # if covariance draw low rank sample\n",
    "        if cov:\n",
    "            cov_mat_sqrt = torch.cat(cov_mat_sqrt_list, dim=1)\n",
    "\n",
    "            cov_sample = cov_mat_sqrt.t().matmul(\n",
    "                cov_mat_sqrt.new_empty(\n",
    "                    (cov_mat_sqrt.size(0),), requires_grad=False\n",
    "                ).normal_()\n",
    "            )\n",
    "            cov_sample /= (self.max_num_models - 1) ** 0.5\n",
    "\n",
    "            rand_sample = var_sample + cov_sample\n",
    "        else:\n",
    "            rand_sample = var_sample\n",
    "\n",
    "        # update sample with mean and scale\n",
    "        sample = mean + scale_sqrt * rand_sample\n",
    "        sample = sample.unsqueeze(0)\n",
    "\n",
    "        # unflatten new sample like the mean sample\n",
    "        samples_list = unflatten_like(sample, mean_list)\n",
    "\n",
    "        for (module, name), sample in zip(self.params, samples_list):\n",
    "            module.__setattr__(name, sample)\n",
    "                               # fix later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "debug start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.num_tasks = 12\n",
    "model = MoleculeModel(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2., -2.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0043, -0.0381, -0.0386,  ..., -0.0121,  0.0527, -0.0059],\n",
      "        [-0.0269,  0.1130,  0.0410,  ...,  0.0831, -0.0566, -0.0933],\n",
      "        [-0.0075, -0.0239,  0.0688,  ...,  0.0139, -0.0381, -0.0666],\n",
      "        ...,\n",
      "        [ 0.0477,  0.0931,  0.0431,  ..., -0.0098,  0.0934,  0.0073],\n",
      "        [ 0.0148,  0.0176, -0.0672,  ..., -0.0106, -0.0575,  0.0559],\n",
      "        [-0.0210,  0.0374,  0.0652,  ..., -0.0119,  0.0493,  0.0782]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0435, -0.0618,  0.0403,  ...,  0.0312, -0.0261, -0.0282],\n",
      "        [-0.0262,  0.0127,  0.0035,  ..., -0.0559, -0.0007,  0.0195],\n",
      "        [ 0.0003, -0.0044, -0.0583,  ...,  0.0221,  0.0904, -0.0456],\n",
      "        ...,\n",
      "        [-0.0243,  0.0544, -0.0868,  ..., -0.0381, -0.0077,  0.0547],\n",
      "        [ 0.0246,  0.0158,  0.0227,  ...,  0.0395,  0.0792,  0.0229],\n",
      "        [ 0.0228,  0.0099, -0.0101,  ...,  0.0490, -0.0160,  0.0206]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0396,  0.0631, -0.0123,  ..., -0.0486, -0.0177,  0.0186],\n",
      "        [-0.0227, -0.0077,  0.0936,  ...,  0.0266,  0.0523, -0.0219],\n",
      "        [ 0.0122, -0.0172,  0.0118,  ...,  0.0838,  0.0221,  0.0168],\n",
      "        ...,\n",
      "        [ 0.0171, -0.0041, -0.0231,  ...,  0.0517,  0.0092, -0.0150],\n",
      "        [ 0.0301,  0.0810,  0.0330,  ..., -0.0773,  0.0580,  0.0330],\n",
      "        [-0.0572,  0.0174, -0.0021,  ...,  0.0441, -0.0253,  0.1024]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0610,  0.0031, -0.0711,  ...,  0.0965,  0.0103,  0.0192],\n",
      "        [-0.0614, -0.0756,  0.0386,  ..., -0.0253, -0.0075, -0.0327],\n",
      "        [-0.0011,  0.0210,  0.0289,  ..., -0.0169, -0.0724, -0.0187],\n",
      "        ...,\n",
      "        [ 0.0685, -0.0260,  0.0524,  ..., -0.0239,  0.0750,  0.0646],\n",
      "        [-0.0302, -0.0852, -0.0203,  ...,  0.0140, -0.0090, -0.0295],\n",
      "        [ 0.0359, -0.0701,  0.0053,  ...,  0.0751, -0.0406, -0.0272]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0694,  0.0502, -0.0218,  ...,  0.0362,  0.0067,  0.0254],\n",
      "        [-0.0933, -0.0784,  0.0735,  ..., -0.0403, -0.0592,  0.0578],\n",
      "        [ 0.0359, -0.0567,  0.0424,  ...,  0.0296, -0.0100, -0.0332],\n",
      "        ...,\n",
      "        [ 0.0102,  0.0759, -0.0505,  ...,  0.0020,  0.0326, -0.0500],\n",
      "        [ 0.0771, -0.0581,  0.0737,  ...,  0.0181, -0.0298, -0.0242],\n",
      "        [ 0.0338,  0.0517, -0.0086,  ..., -0.0077, -0.0274,  0.0174]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1861,  0.0632, -0.0699,  ..., -0.0215, -0.0094, -0.0030],\n",
      "        [-0.0597, -0.0758, -0.0205,  ..., -0.0441,  0.0246,  0.0751],\n",
      "        [-0.0563, -0.0637, -0.0379,  ..., -0.0449,  0.0101, -0.0152],\n",
      "        ...,\n",
      "        [ 0.0748,  0.0086, -0.0240,  ..., -0.0103,  0.0479,  0.0765],\n",
      "        [ 0.2091, -0.0311, -0.0049,  ...,  0.0948, -0.0331, -0.0642],\n",
      "        [ 0.0016,  0.0506, -0.1329,  ..., -0.0946, -0.0067,  0.0939]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_swag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7e23bf14f42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_swag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_swag' is not defined"
     ]
    }
   ],
   "source": [
    "model = train_swag(model, train_data_loader, loss_func, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "swag_model = SWAG(\n",
    "    model,\n",
    "    no_cov_mat=True,\n",
    "    max_num_models=12,\n",
    "    var_clamp=1e-30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "swag_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeModel(\n",
       "  (encoder): MPN(\n",
       "    (encoder): MPNEncoder(\n",
       "      (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "      (act_func): ReLU()\n",
       "      (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
       "      (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
       "      (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (ffn): Sequential(\n",
       "    (0): Dropout(p=0.0, inplace=False)\n",
       "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.0, inplace=False)\n",
       "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.0, inplace=False)\n",
       "    (7): Linear(in_features=500, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train_swag(model, train_data_loader, loss_func, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SWAG(\n",
       "  (base): MoleculeModel(\n",
       "    (encoder): MPN(\n",
       "      (encoder): MPNEncoder(\n",
       "        (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        (act_func): ReLU()\n",
       "        (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
       "        (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
       "        (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (ffn): Sequential(\n",
       "      (0): Dropout(p=0.0, inplace=False)\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "      (4): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Dropout(p=0.0, inplace=False)\n",
       "      (7): Linear(in_features=500, out_features=12, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Parameter containing:\n",
      "tensor([[-0.0182, -0.0381,  0.0127,  ..., -0.0065, -0.0396,  0.0166],\n",
      "        [-0.0304, -0.0629,  0.0022,  ..., -0.0678, -0.0370, -0.0097],\n",
      "        [-0.0727,  0.0735,  0.0108,  ...,  0.0333, -0.0346, -0.0797],\n",
      "        ...,\n",
      "        [ 0.0304, -0.0845, -0.0002,  ..., -0.0003,  0.0106, -0.0279],\n",
      "        [ 0.0294, -0.0279,  0.0912,  ...,  0.0365,  0.0401,  0.0307],\n",
      "        [-0.0034, -0.0054,  0.1165,  ..., -0.0123,  0.0171, -0.1042]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0009,  0.0470, -0.0100,  ..., -0.0127,  0.0477,  0.0186],\n",
      "        [ 0.0137, -0.0434, -0.0915,  ...,  0.0402, -0.0641,  0.0251],\n",
      "        [-0.0234,  0.0620,  0.0064,  ...,  0.0433, -0.0044,  0.0372],\n",
      "        ...,\n",
      "        [ 0.0712, -0.0261,  0.0090,  ...,  0.0073,  0.0030,  0.0396],\n",
      "        [-0.0305, -0.0166, -0.0011,  ..., -0.0333, -0.0445, -0.0949],\n",
      "        [ 0.0537, -0.0483, -0.0288,  ...,  0.0776,  0.0253,  0.0504]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0102,  0.0560, -0.0355,  ..., -0.0406, -0.0304,  0.0343],\n",
      "        [-0.0036, -0.0067, -0.0216,  ...,  0.0164, -0.0098, -0.0154],\n",
      "        [ 0.0327, -0.0397,  0.0519,  ...,  0.0348,  0.0988,  0.0190],\n",
      "        ...,\n",
      "        [-0.0303, -0.0632,  0.0224,  ...,  0.0677, -0.0423, -0.0407],\n",
      "        [ 0.0393,  0.0203,  0.0221,  ..., -0.0081,  0.0371,  0.0304],\n",
      "        [ 0.0327, -0.0055, -0.0900,  ..., -0.0332, -0.0383,  0.0033]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0007,  0.0380, -0.0349,  ..., -0.0603, -0.0466,  0.0109],\n",
      "        [ 0.0118,  0.0018, -0.0395,  ...,  0.0105, -0.0235,  0.0760],\n",
      "        [-0.0489,  0.0041,  0.0525,  ..., -0.0906,  0.0718, -0.0640],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0103, -0.0156,  ...,  0.0429, -0.0573, -0.0312],\n",
      "        [-0.1027, -0.0546,  0.0064,  ..., -0.0445, -0.0582, -0.0203],\n",
      "        [-0.0355,  0.0063,  0.0159,  ..., -0.0167, -0.0279,  0.0334]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0535, -0.0866,  0.0481,  ...,  0.0331, -0.0321, -0.0228],\n",
      "        [ 0.0078, -0.0842,  0.0095,  ..., -0.0459, -0.0328,  0.0574],\n",
      "        [-0.0215,  0.0054,  0.0642,  ...,  0.0464, -0.0173,  0.0592],\n",
      "        ...,\n",
      "        [ 0.0041, -0.0898,  0.1130,  ..., -0.0148,  0.0207, -0.0086],\n",
      "        [-0.0294,  0.0788, -0.0181,  ...,  0.0654, -0.0040,  0.0064],\n",
      "        [-0.0690,  0.0436,  0.0235,  ..., -0.0851, -0.0803,  0.0403]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1238, -0.0093,  0.0655,  ..., -0.0429,  0.0346,  0.0675],\n",
      "        [-0.0979,  0.0110, -0.0413,  ...,  0.0853, -0.0416, -0.0701],\n",
      "        [ 0.0335, -0.1089, -0.0830,  ..., -0.1791,  0.0427,  0.0229],\n",
      "        ...,\n",
      "        [-0.1516,  0.0509,  0.0318,  ..., -0.1211, -0.0500, -0.0345],\n",
      "        [-0.0657,  0.0519, -0.0184,  ..., -0.0406, -0.0482, -0.1288],\n",
      "        [ 0.0353, -0.0348, -0.0725,  ..., -0.0733, -0.0787, -0.0099]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in base_model.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MPNEncoder(\n",
      "  (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "  (act_func): ReLU()\n",
      "  (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
      "  (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
      "  (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
      "), 'cached_zero_vector')\n",
      "(Linear(in_features=147, out_features=500, bias=False), 'weight')\n",
      "(Linear(in_features=500, out_features=500, bias=False), 'weight')\n",
      "(Linear(in_features=633, out_features=500, bias=True), 'weight')\n",
      "(Linear(in_features=633, out_features=500, bias=True), 'bias')\n",
      "(Linear(in_features=500, out_features=500, bias=True), 'weight')\n",
      "(Linear(in_features=500, out_features=500, bias=True), 'bias')\n",
      "(Linear(in_features=500, out_features=500, bias=True), 'weight')\n",
      "(Linear(in_features=500, out_features=500, bias=True), 'bias')\n",
      "(Linear(in_features=500, out_features=12, bias=True), 'weight')\n",
      "(Linear(in_features=500, out_features=12, bias=True), 'bias')\n"
     ]
    }
   ],
   "source": [
    "for i in swag_model.params:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPNEncoder(\n",
      "  (dropout_layer): Dropout(p=0.0, inplace=False)\n",
      "  (act_func): ReLU()\n",
      "  (W_i): Linear(in_features=147, out_features=500, bias=False)\n",
      "  (W_h): Linear(in_features=500, out_features=500, bias=False)\n",
      "  (W_o): Linear(in_features=633, out_features=500, bias=True)\n",
      ")\n",
      "cached_zero_vector\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "----\n",
      "Linear(in_features=147, out_features=500, bias=False)\n",
      "weight\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[-0.0182, -0.0381,  0.0127,  ..., -0.0065, -0.0396,  0.0166],\n",
      "        [-0.0304, -0.0629,  0.0022,  ..., -0.0678, -0.0370, -0.0097],\n",
      "        [-0.0727,  0.0735,  0.0108,  ...,  0.0333, -0.0346, -0.0797],\n",
      "        ...,\n",
      "        [ 0.0304, -0.0845, -0.0002,  ..., -0.0003,  0.0106, -0.0279],\n",
      "        [ 0.0294, -0.0279,  0.0912,  ...,  0.0365,  0.0401,  0.0307],\n",
      "        [-0.0034, -0.0054,  0.1165,  ..., -0.0123,  0.0171, -0.1042]])\n",
      "----\n",
      "Linear(in_features=500, out_features=500, bias=False)\n",
      "weight\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 0.0009,  0.0470, -0.0100,  ..., -0.0127,  0.0477,  0.0186],\n",
      "        [ 0.0137, -0.0434, -0.0915,  ...,  0.0402, -0.0641,  0.0251],\n",
      "        [-0.0234,  0.0620,  0.0064,  ...,  0.0433, -0.0044,  0.0372],\n",
      "        ...,\n",
      "        [ 0.0712, -0.0261,  0.0090,  ...,  0.0073,  0.0030,  0.0396],\n",
      "        [-0.0305, -0.0166, -0.0011,  ..., -0.0333, -0.0445, -0.0949],\n",
      "        [ 0.0537, -0.0483, -0.0288,  ...,  0.0776,  0.0253,  0.0504]])\n",
      "----\n",
      "Linear(in_features=633, out_features=500, bias=True)\n",
      "weight\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 0.0102,  0.0560, -0.0355,  ..., -0.0406, -0.0304,  0.0343],\n",
      "        [-0.0036, -0.0067, -0.0216,  ...,  0.0164, -0.0098, -0.0154],\n",
      "        [ 0.0327, -0.0397,  0.0519,  ...,  0.0348,  0.0988,  0.0190],\n",
      "        ...,\n",
      "        [-0.0303, -0.0632,  0.0224,  ...,  0.0677, -0.0423, -0.0407],\n",
      "        [ 0.0393,  0.0203,  0.0221,  ..., -0.0081,  0.0371,  0.0304],\n",
      "        [ 0.0327, -0.0055, -0.0900,  ..., -0.0332, -0.0383,  0.0033]])\n",
      "----\n",
      "Linear(in_features=633, out_features=500, bias=True)\n",
      "bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "----\n",
      "Linear(in_features=500, out_features=500, bias=True)\n",
      "weight\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 0.0007,  0.0380, -0.0349,  ..., -0.0603, -0.0466,  0.0109],\n",
      "        [ 0.0118,  0.0018, -0.0395,  ...,  0.0105, -0.0235,  0.0760],\n",
      "        [-0.0489,  0.0041,  0.0525,  ..., -0.0906,  0.0718, -0.0640],\n",
      "        ...,\n",
      "        [ 0.0140,  0.0103, -0.0156,  ...,  0.0429, -0.0573, -0.0312],\n",
      "        [-0.1027, -0.0546,  0.0064,  ..., -0.0445, -0.0582, -0.0203],\n",
      "        [-0.0355,  0.0063,  0.0159,  ..., -0.0167, -0.0279,  0.0334]])\n",
      "----\n",
      "Linear(in_features=500, out_features=500, bias=True)\n",
      "bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "----\n",
      "Linear(in_features=500, out_features=500, bias=True)\n",
      "weight\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[ 0.0535, -0.0866,  0.0481,  ...,  0.0331, -0.0321, -0.0228],\n",
      "        [ 0.0078, -0.0842,  0.0095,  ..., -0.0459, -0.0328,  0.0574],\n",
      "        [-0.0215,  0.0054,  0.0642,  ...,  0.0464, -0.0173,  0.0592],\n",
      "        ...,\n",
      "        [ 0.0041, -0.0898,  0.1130,  ..., -0.0148,  0.0207, -0.0086],\n",
      "        [-0.0294,  0.0788, -0.0181,  ...,  0.0654, -0.0040,  0.0064],\n",
      "        [-0.0690,  0.0436,  0.0235,  ..., -0.0851, -0.0803,  0.0403]])\n",
      "----\n",
      "Linear(in_features=500, out_features=500, bias=True)\n",
      "bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "----\n",
      "Linear(in_features=500, out_features=12, bias=True)\n",
      "weight\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[-0.1238, -0.0093,  0.0655,  ..., -0.0429,  0.0346,  0.0675],\n",
      "        [-0.0979,  0.0110, -0.0413,  ...,  0.0853, -0.0416, -0.0701],\n",
      "        [ 0.0335, -0.1089, -0.0830,  ..., -0.1791,  0.0427,  0.0229],\n",
      "        ...,\n",
      "        [-0.1516,  0.0509,  0.0318,  ..., -0.1211, -0.0500, -0.0345],\n",
      "        [-0.0657,  0.0519, -0.0184,  ..., -0.0406, -0.0482, -0.1288],\n",
      "        [ 0.0353, -0.0348, -0.0725,  ..., -0.0733, -0.0787, -0.0099]])\n",
      "----\n",
      "Linear(in_features=500, out_features=12, bias=True)\n",
      "bias\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for (module, name), base_param in zip(swag_model.params, base_model.parameters()):\n",
    "    mean = module.__getattr__(\"%s_mean\" % name)\n",
    "    sq_mean = module.__getattr__(\"%s_sq_mean\" % name)\n",
    "    print(module)\n",
    "    print(name)\n",
    "    \n",
    "    # first moment\n",
    "    print(mean)\n",
    "    print(base_param.data)\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (147) must match the size of tensor b (500) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2566e5220d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mswag_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/chempropBayes/chemprop/bayes/swag.py\u001b[0m in \u001b[0;36mcollect_model\u001b[0;34m(self, base_model)\u001b[0m\n\u001b[1;32m    210\u001b[0m             ) + base_param.data / (self.n_models.item() + 1.0)\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;31m# second moment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             sq_mean = sq_mean * self.n_models.item() / (\n\u001b[1;32m    214\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (147) must match the size of tensor b (500) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for (module, name), base_param in zip(self.params, base_model.parameters()):\n",
    "    mean = module.__getattr__(\"%s_mean\" % name)\n",
    "    sq_mean = module.__getattr__(\"%s_sq_mean\" % name)\n",
    "\n",
    "    # first moment\n",
    "    mean = mean * self.n_models.item() / (\n",
    "        self.n_models.item() + 1.0\n",
    "    ) + base_param.data / (self.n_models.item() + 1.0)\n",
    "\n",
    "    # second moment\n",
    "    sq_mean = sq_mean * self.n_models.item() / (\n",
    "        self.n_models.item() + 1.0\n",
    "    ) + base_param.data ** 2 / (self.n_models.item() + 1.0)\n",
    "\n",
    "    # square root of covariance matrix\n",
    "    if self.no_cov_mat is False:\n",
    "        cov_mat_sqrt = module.__getattr__(\"%s_cov_mat_sqrt\" % name)\n",
    "\n",
    "        # block covariance matrices, store deviation from current mean\n",
    "        dev = (base_param.data - mean).view(-1, 1)\n",
    "        cov_mat_sqrt = torch.cat((cov_mat_sqrt, dev.view(-1, 1).t()), dim=0)\n",
    "\n",
    "        # remove first column if we have stored too many models\n",
    "        if (self.n_models.item() + 1) > self.max_num_models:\n",
    "            cov_mat_sqrt = cov_mat_sqrt[1:, :]\n",
    "        module.__setattr__(\"%s_cov_mat_sqrt\" % name, cov_mat_sqrt)\n",
    "\n",
    "    module.__setattr__(\"%s_mean\" % name, mean)\n",
    "    module.__setattr__(\"%s_sq_mean\" % name, sq_mean)\n",
    "self.n_models.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies swag_parameters function to each submodule of base (loop over submodules is implicit)\n",
    "swag_model.base.apply(\n",
    "    lambda module: swag_parameters(\n",
    "        module=module, params=swag_model.params, no_cov_mat=swag_model.no_cov_mat\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=147, out_features=500, bias=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag_model.params[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=147, out_features=500, bias=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag_model.base.encoder.encoder.W_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "swag_model.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swag_parameters(module, params, no_cov_mat=True):\n",
    "    \"\"\"\n",
    "    module: submodule of base model\n",
    "    params: list of params\n",
    "    no_cov_mat: True means SWAG DIAG\n",
    "    \"\"\"\n",
    "    \n",
    "    # for each module (i.e. layer), list is a list of the parameter groups e.g. ['weight', 'bias'] or ['c z v']\n",
    "    # we loop through the names of each list\n",
    "    for name in list(module._parameters.keys()):\n",
    "        \n",
    "        # if there are no parameters associated with the name, continue\n",
    "        if module._parameters[name] is None:\n",
    "            continue\n",
    "            \n",
    "        # data is an extracted parameter vector    \n",
    "        data = module._parameters[name].data\n",
    "        \n",
    "\n",
    "    print('done one layer thing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swag_parameters(module, params, no_cov_mat=True):\n",
    "    \"\"\"\n",
    "    module: submodule of base model\n",
    "    params: list of params\n",
    "    no_cov_mat: True means SWAG DIAG\n",
    "    \"\"\"\n",
    "    \n",
    "    # for each module (i.e. layer), list is a list of the parameter groups e.g. ['weight', 'bias'] or ['c z v']\n",
    "    # we loop through the names of each list\n",
    "    for name in list(module._parameters.keys()):\n",
    "        \n",
    "        # if there are no parameters associated with the name, continue\n",
    "        if module._parameters[name] is None:\n",
    "            continue\n",
    "            \n",
    "        # data is an extracted parameter vector    \n",
    "        data = module._parameters[name].data\n",
    "        \n",
    "        # we're removing name and associated params from module._parameters\n",
    "        module._parameters.pop(name)\n",
    "        \n",
    "        # registers buffers for first moment and second moment\n",
    "        # initialised at zero?\n",
    "        module.register_buffer(\"%s_mean\" % name, data.new(data.size()).zero_())\n",
    "        module.register_buffer(\"%s_sq_mean\" % name, data.new(data.size()).zero_())\n",
    "        \n",
    "        # if full SWAG, registers D (sqrt of covariance matrix)\n",
    "        if no_cov_mat is False:\n",
    "            module.register_buffer(\n",
    "                \"%s_cov_mat_sqrt\" % name, data.new_empty((0, data.numel())).zero_()\n",
    "            )\n",
    "\n",
    "        # append to list of SWAG parameters\n",
    "        params.append((module, name))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swag_parameters(module, params, no_cov_mat=True):\n",
    "    \"\"\"\n",
    "    module: submodule of base model\n",
    "    params: list of params\n",
    "    no_cov_mat: True means SWAG DIAG\n",
    "    \"\"\"\n",
    "    for name in list(module._parameters.keys()):\n",
    "        if module._parameters[name] is None:\n",
    "            continue\n",
    "        data = module._parameters[name].data\n",
    "        module._parameters.pop(name)\n",
    "        \n",
    "        # registers buffers for first moment and second moment\n",
    "        # initialised at zero?\n",
    "        module.register_buffer(\"%s_mean\" % name, data.new(data.size()).zero_())\n",
    "        module.register_buffer(\"%s_sq_mean\" % name, data.new(data.size()).zero_())\n",
    "        \n",
    "        # if full SWAG, registers D (sqrt of covariance matrix)\n",
    "        if no_cov_mat is False:\n",
    "            module.register_buffer(\n",
    "                \"%s_cov_mat_sqrt\" % name, data.new_empty((0, data.numel())).zero_()\n",
    "            )\n",
    "\n",
    "        # append to list of SWAG parameters\n",
    "        params.append((module, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_model(self, base_model):\n",
    "    \"\"\"\n",
    "    updates first moment, second moment and sqrt of cov matrix\n",
    "    \"\"\"\n",
    "    for (module, name), base_param in zip(self.params, base_model.parameters()):\n",
    "        mean = module.__getattr__(\"%s_mean\" % name)\n",
    "        sq_mean = module.__getattr__(\"%s_sq_mean\" % name)\n",
    "\n",
    "        # first moment\n",
    "        mean = mean * self.n_models.item() / (\n",
    "            self.n_models.item() + 1.0\n",
    "        ) + base_param.data / (self.n_models.item() + 1.0)\n",
    "\n",
    "        # second moment\n",
    "        sq_mean = sq_mean * self.n_models.item() / (\n",
    "            self.n_models.item() + 1.0\n",
    "        ) + base_param.data ** 2 / (self.n_models.item() + 1.0)\n",
    "\n",
    "        # square root of covariance matrix\n",
    "        if self.no_cov_mat is False:\n",
    "            cov_mat_sqrt = module.__getattr__(\"%s_cov_mat_sqrt\" % name)\n",
    "\n",
    "            # block covariance matrices, store deviation from current mean\n",
    "            dev = (base_param.data - mean).view(-1, 1)\n",
    "            cov_mat_sqrt = torch.cat((cov_mat_sqrt, dev.view(-1, 1).t()), dim=0)\n",
    "\n",
    "            # remove first column if we have stored too many models\n",
    "            if (self.n_models.item() + 1) > self.max_num_models:\n",
    "                cov_mat_sqrt = cov_mat_sqrt[1:, :]\n",
    "            module.__setattr__(\"%s_cov_mat_sqrt\" % name, cov_mat_sqrt)\n",
    "\n",
    "        module.__setattr__(\"%s_mean\" % name, mean)\n",
    "        module.__setattr__(\"%s_sq_mean\" % name, sq_mean)\n",
    "    self.n_models.add_(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
